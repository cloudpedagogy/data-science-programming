{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNB93kML14Kkc1xyo573ZDS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cloudpedagogy/data-science-programming/blob/main/data-analysis-pandas/03_Data_Exploration_and_Descriptive_Statistics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Exploration and Descriptive Statistics\n"
      ],
      "metadata": {
        "id": "VjKT9yiwUjDp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview"
      ],
      "metadata": {
        "id": "EfeI_MdeKoah"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Data exploration and descriptive statistics are essential steps in analyzing and understanding datasets. They provide valuable insights into the underlying patterns, characteristics, and relationships within the data. Python programming offers powerful libraries and tools for performing data exploration and generating descriptive statistics, enabling data scientists and analysts to gain a comprehensive understanding of their datasets.\n",
        "\n",
        "Data exploration involves examining and visualizing the data to discover its structure, uncover patterns, identify potential issues or outliers, and gain insights into the relationships between variables. It helps in forming hypotheses and guiding further analysis. Python libraries such as Pandas, NumPy, and Matplotlib provide a wide range of functions and methods for exploring and visualizing data.\n",
        "\n",
        "Descriptive statistics, on the other hand, involves summarizing and describing the main characteristics of the data using statistical measures. These measures provide a numerical representation of the dataset's central tendency, dispersion, and shape. Descriptive statistics can include measures such as mean, median, mode, variance, standard deviation, percentiles, and more. Python libraries like NumPy and Pandas offer functions to calculate these statistics quickly and efficiently.\n",
        "\n",
        "Python's Pandas library is particularly useful for data exploration and descriptive statistics. It provides powerful data structures, such as DataFrames, which allow for efficient manipulation and analysis of tabular data. Pandas offers a wide range of functions to filter, sort, group, aggregate, and transform data, making it easier to extract meaningful insights from the dataset.\n",
        "\n",
        "Visualization is an integral part of data exploration and descriptive statistics. Python's Matplotlib library, along with other visualization libraries like Seaborn and Plotly, enables the creation of various types of plots, charts, and graphs. These visual representations help in understanding the data distribution, identifying outliers, and visualizing relationships between variables.\n",
        "\n",
        "In summary, data exploration and descriptive statistics in Python programming are crucial steps in understanding and analyzing datasets. They allow data scientists and analysts to gain insights into the data's characteristics, patterns, and relationships. Python libraries such as Pandas, NumPy, Matplotlib, Seaborn, and Plotly provide powerful tools to perform data exploration, calculate descriptive statistics, and visualize the data effectively. These techniques lay the foundation for further analysis and modeling tasks in data science and help in making informed decisions based on the data."
      ],
      "metadata": {
        "id": "jCvtQD3iKuOz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory data analysis techniques\n"
      ],
      "metadata": {
        "id": "ebp7ULrYOOqA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Exploratory Data Analysis (EDA) is a crucial step in the data analysis process. It involves understanding the data, identifying patterns, detecting outliers, and gaining insights into the dataset. Pandas provides several techniques to perform EDA effectively. Here's an example of some common EDA techniques using the Pima Indian Diabetes dataset:\n"
      ],
      "metadata": {
        "id": "GQXa3AvbUmqy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the Pima Indian Diabetes dataset\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "column_names = [\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", \"Age\", \"Outcome\"]\n",
        "dataset = pd.read_csv(url, names=column_names)\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(\"First few rows of the dataset:\")\n",
        "print(dataset.head())\n",
        "\n",
        "# Get summary statistics of the dataset\n",
        "print(\"\\nSummary statistics:\")\n",
        "print(dataset.describe())\n",
        "\n",
        "# Visualize the distribution of the 'Glucose' feature using a histogram\n",
        "plt.hist(dataset['Glucose'], bins=10, edgecolor='black')\n",
        "plt.xlabel('Glucose')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Glucose')\n",
        "plt.show()\n",
        "\n",
        "# Explore the correlation between features using a correlation matrix\n",
        "correlation_matrix = dataset.corr()\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.imshow(correlation_matrix, cmap='coolwarm', interpolation='none')\n",
        "plt.colorbar()\n",
        "plt.xticks(range(len(column_names)), column_names, rotation=45)\n",
        "plt.yticks(range(len(column_names)), column_names)\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0TcF6xOmUqk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we first load the Pima Indian Diabetes dataset using Pandas. Then, we perform the following EDA techniques:\n",
        "\n",
        "1. Displaying the first few rows of the dataset: This gives an initial understanding of the data and its structure.\n",
        "\n",
        "2. Obtaining summary statistics: Using `describe()`, we get summary statistics such as count, mean, standard deviation, minimum, maximum, and quartiles for each numerical feature in the dataset.\n",
        "\n",
        "3. Visualizing the distribution of a feature: We create a histogram using `plt.hist()` to visualize the distribution of the 'Glucose' feature. This helps in understanding the spread and shape of the data.\n",
        "\n",
        "4. Exploring the correlation between features: We compute the correlation matrix using `dataset.corr()` and create a heatmap using `plt.imshow()`. This visual representation allows us to identify patterns and relationships between different features.\n"
      ],
      "metadata": {
        "id": "55UlRMhwUxWf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary statistics and descriptive analysis\n"
      ],
      "metadata": {
        "id": "c61BwZKQLJ5f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary statistics\n"
      ],
      "metadata": {
        "id": "hfRsoF8KOSBd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Summary statistics in Pandas provide a concise overview of the distribution and properties of a dataset. It includes common statistical measures such as mean, median, mode, standard deviation, minimum, maximum, and quartiles. Pandas provides a convenient way to calculate these summary statistics using the `describe()` method.\n",
        "\n",
        "Here's an example of calculating summary statistics on the Pima Indian Diabetes dataset:\n"
      ],
      "metadata": {
        "id": "UgtRgmGIU0jg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the Pima Indian Diabetes dataset\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "column_names = [\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", \"Age\", \"Outcome\"]\n",
        "dataset = pd.read_csv(url, names=column_names)\n",
        "\n",
        "# Calculate summary statistics\n",
        "summary_stats = dataset.describe()\n",
        "\n",
        "# Print the summary statistics\n",
        "print(summary_stats)\n"
      ],
      "metadata": {
        "id": "fVJNqkO_U4mV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we load the Pima Indian Diabetes dataset using Pandas. We then use the `describe()` method on the dataset to calculate the summary statistics. The `describe()` method automatically computes and returns the count, mean, standard deviation, minimum, quartiles, and maximum for each numerical column in the dataset. The resulting summary_stats DataFrame contains these statistics.\n",
        "\n",
        "Finally, we print the summary statistics using `print(summary_stats)` to display the output. The summary statistics provide a quick overview of the dataset, including measures such as count (number of non-null values), mean, standard deviation, minimum, quartiles (25th, 50th, and 75th percentiles), and maximum values for each numeric column in the dataset.\n"
      ],
      "metadata": {
        "id": "IJy6CsRNU8JR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Descriptive analysis\n"
      ],
      "metadata": {
        "id": "4kBkmlhvOWCN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Descriptive analysis in pandas involves computing various statistics and summaries to gain insights into the data. Pandas provides a range of functions to perform descriptive analysis, including measures of central tendency, dispersion, correlation, and more. These functions allow you to understand the distribution, relationships, and overall characteristics of the dataset.\n",
        "\n",
        "Here's an example of performing descriptive analysis on the Pima Indian Diabetes dataset using pandas:\n"
      ],
      "metadata": {
        "id": "Az5s7zmIVp6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the Pima Indian Diabetes dataset\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "column_names = [\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", \"Age\", \"Outcome\"]\n",
        "dataset = pd.read_csv(url, names=column_names)\n",
        "\n",
        "# Compute descriptive statistics\n",
        "summary = dataset.describe()\n",
        "\n",
        "# Compute correlation matrix\n",
        "correlation_matrix = dataset.corr()\n",
        "\n",
        "# Print the descriptive statistics and correlation matrix\n",
        "print(\"Descriptive Statistics:\")\n",
        "print(summary)\n",
        "print(\"\\nCorrelation Matrix:\")\n",
        "print(correlation_matrix)\n"
      ],
      "metadata": {
        "id": "sQDIp46HVuvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we load the Pima Indian Diabetes dataset using Pandas. We then use two common methods for descriptive analysis:\n",
        "\n",
        "1. `describe()`: This function computes various statistics, including count, mean, standard deviation, minimum, quartiles, and maximum for each column in the dataset. The resulting summary provides an overview of the dataset's distribution.\n",
        "2. `corr()`: This function calculates the correlation between different columns of the dataset. The resulting correlation matrix shows the strength and direction of the linear relationship between variables.\n",
        "\n",
        "We use these functions on the dataset and store the results in `summary` and `correlation_matrix` variables. Finally, we print the descriptive statistics and correlation matrix to examine the dataset's characteristics and relationships between variables.\n",
        "\n",
        "Descriptive analysis provides valuable insights into the dataset, enabling you to understand the data's distribution, identify potential issues, and explore relationships between variables.\n"
      ],
      "metadata": {
        "id": "A_kO2_19Vy7q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grouping and aggregation operations\n"
      ],
      "metadata": {
        "id": "NM3qJgTsN6EO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Grouping\n"
      ],
      "metadata": {
        "id": "1Mu2is_OOZ3B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Grouping in pandas refers to the process of splitting data into groups based on one or more categorical variables and applying calculations or operations within each group. It allows for aggregating and summarizing data by categories, enabling insights and analysis at a higher level of granularity.\n",
        "\n",
        "Here's an example of grouping using the Pima Indian Diabetes dataset:\n"
      ],
      "metadata": {
        "id": "yd1Magk7V3pj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the Pima Indian Diabetes dataset\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "column_names = [\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", \"Age\", \"Outcome\"]\n",
        "dataset = pd.read_csv(url, names=column_names)\n",
        "\n",
        "# Group the data by the 'Outcome' column and calculate the mean of other numeric columns\n",
        "grouped_data = dataset.groupby('Outcome').mean()\n",
        "\n",
        "# Print the grouped data\n",
        "print(grouped_data)\n"
      ],
      "metadata": {
        "id": "dpa8NMMMV9i0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we load the Pima Indian Diabetes dataset using Pandas. We then group the data by the 'Outcome' column, which contains binary values (0 or 1) indicating whether a person has diabetes or not. The `groupby()` function is used to group the data based on this column.\n",
        "\n",
        "After grouping, we calculate the mean of the other numeric columns ('Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', and 'Age') within each group. The `mean()` function is applied to each group, calculating the average value for each column.\n",
        "\n",
        "Finally, we print the grouped data, which displays the mean values for each numeric column, separated by the 'Outcome' groups. This provides insights into how the different variables relate to the outcome of diabetes in the dataset.\n"
      ],
      "metadata": {
        "id": "LOJH2h19WCie"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aggregation operations\n"
      ],
      "metadata": {
        "id": "r54RScS7N9F1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Aggregation operations in Pandas allow you to compute summary statistics or perform calculations on groups of data. These operations provide valuable insights into the data distribution, central tendency, and other statistical measures. Pandas provides a range of aggregation functions, such as mean, sum, count, max, min, etc.\n",
        "\n",
        "Here's an example of aggregation operations on the Pima Indian Diabetes dataset:\n"
      ],
      "metadata": {
        "id": "WNexzle-WGmf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the Pima Indian Diabetes dataset\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "column_names = [\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", \"Age\", \"Outcome\"]\n",
        "dataset = pd.read_csv(url, names=column_names)\n",
        "\n",
        "# Calculate the mean glucose level for all records\n",
        "mean_glucose = dataset['Glucose'].mean()\n",
        "print(\"Mean glucose level:\", mean_glucose)\n",
        "\n",
        "# Calculate the maximum BMI value\n",
        "max_bmi = dataset['BMI'].max()\n",
        "print(\"Maximum BMI value:\", max_bmi)\n",
        "\n",
        "# Count the number of records for each outcome (0 or 1)\n",
        "outcome_counts = dataset['Outcome'].value_counts()\n",
        "print(\"Outcome counts:\")\n",
        "print(outcome_counts)\n"
      ],
      "metadata": {
        "id": "HlejyISGWKCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we load the Pima Indian Diabetes dataset using Pandas. We perform several aggregation operations on different columns:\n",
        "\n",
        "1. `mean_glucose = dataset['Glucose'].mean()`: Calculates the mean (average) glucose level for all records in the 'Glucose' column.\n",
        "\n",
        "2. `max_bmi = dataset['BMI'].max()`: Finds the maximum BMI value from the 'BMI' column.\n",
        "\n",
        "3. `outcome_counts = dataset['Outcome'].value_counts()`: Counts the number of records for each outcome (0 or 1) in the 'Outcome' column using the `value_counts()` function.\n",
        "\n",
        "We then print the results to see the computed summary statistics and outcome counts.\n",
        "\n",
        "By applying aggregation operations, you can gain valuable insights into the dataset, understand the distribution of different variables, and make informed decisions based on the computed summary statistics.\n"
      ],
      "metadata": {
        "id": "XmFMQe2AWOZ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data visualization using Pandas and Matplotlib\n"
      ],
      "metadata": {
        "id": "f7vz_eWjOEtj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Data visualization is an essential part of data analysis, allowing you to gain insights and communicate findings effectively. In Python, you can use Pandas for data manipulation and Matplotlib for creating various types of plots. Here's an example of data visualization using Pandas and Matplotlib on the Pima Indian Diabetes dataset:\n"
      ],
      "metadata": {
        "id": "dXxrt_VUWRm1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the Pima Indian Diabetes dataset\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "column_names = [\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", \"Age\", \"Outcome\"]\n",
        "dataset = pd.read_csv(url, names=column_names)\n",
        "\n",
        "# Histogram of the Glucose levels\n",
        "plt.hist(dataset['Glucose'], bins=10, color='skyblue')\n",
        "plt.xlabel('Glucose')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Glucose Levels')\n",
        "plt.show()\n",
        "\n",
        "# Boxplot of BMI by Outcome\n",
        "dataset.boxplot(column='BMI', by='Outcome', grid=False)\n",
        "plt.xlabel('Outcome')\n",
        "plt.ylabel('BMI')\n",
        "plt.title('BMI Distribution by Outcome')\n",
        "plt.suptitle('')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Pii7wpz4WVvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we load the Pima Indian Diabetes dataset using Pandas. We then create two different types of plots using Matplotlib.\n",
        "\n",
        "1. Histogram: We plot a histogram of the 'Glucose' levels using `plt.hist()`. The `bins` parameter determines the number of bins in the histogram. We set the x-axis label to 'Glucose', the y-axis label to 'Frequency', and the title of the plot to 'Distribution of Glucose Levels'.\n",
        "\n",
        "2. Boxplot: We create a boxplot of the 'BMI' values grouped by the 'Outcome' using `dataset.boxplot()`. The `column` parameter specifies the column to plot, and the `by` parameter specifies the grouping column. We customize the x-axis label, y-axis label, title, and remove the default subplot title using `plt.suptitle('')`.\n",
        "\n",
        "Finally, we use `plt.show()` to display each plot separately.\n",
        "\n",
        "These examples demonstrate how to create basic visualizations using Pandas and Matplotlib. You can explore further by customizing plots, creating different types of visualizations, and adding more features to suit your analysis needs.\n"
      ],
      "metadata": {
        "id": "rrX3bU78WaHv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reflection Points"
      ],
      "metadata": {
        "id": "NTx1ZEFfjM_5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Exploratory Data Analysis Techniques**:\n",
        "   - How can exploratory data analysis help in understanding a dataset?\n",
        "   - What are some common techniques used in exploratory data analysis?\n",
        "   - How can you handle missing values during exploratory data analysis?\n",
        "   - Can you provide examples of exploratory data analysis techniques you've used in the past?\n",
        "\n",
        "2. **Summary Statistics and Descriptive Analysis**:\n",
        "   - What is the purpose of summary statistics in data analysis?\n",
        "   - How do you calculate measures of central tendency, such as mean, median, and mode, using Python?\n",
        "   - What are some commonly used measures of dispersion, such as variance and standard deviation?\n",
        "   - How can you interpret and use summary statistics to gain insights from a dataset?\n",
        "\n",
        "3. **Grouping and Aggregation Operations**:\n",
        "   - What is the significance of grouping and aggregation operations in data analysis?\n",
        "   - How can you group data based on one or more variables using Pandas?\n",
        "   - What are some commonly used aggregation functions, such as count, sum, mean, and max?\n",
        "   - Can you provide examples of situations where grouping and aggregation operations are useful?\n",
        "\n",
        "4. **Data Visualization using Pandas and Matplotlib**:\n",
        "   - Why is data visualization important in data analysis?\n",
        "   - How can you create basic visualizations, such as line plots, bar plots, and scatter plots, using Pandas and Matplotlib?\n",
        "   - What are the key components of a well-designed data visualization?\n",
        "   - Can you explain the concept of data visualization best practices, such as choosing appropriate chart types and labeling axes?\n"
      ],
      "metadata": {
        "id": "lo0fjhAKjS3E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise"
      ],
      "metadata": {
        "id": "IEz8s0WIcp5P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. Load the dataset from the provided URL.\n",
        "2. Perform basic data exploration to understand the dataset.\n",
        "3. Calculate and display descriptive statistics for the dataset.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pccJMIsRcz5S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sample Solution\n"
      ],
      "metadata": {
        "id": "26Us5xffe6V7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "# Columns in the dataset\n",
        "columns = ['pregnancies', 'glucose', 'blood_pressure', 'skin_thickness', 'insulin', 'bmi', 'diabetes_pedigree', 'age', 'outcome']\n",
        "# Load the data into a Pandas DataFrame\n",
        "df = pd.read_csv(url, names=columns)\n",
        "\n",
        "# Step 2: Data Exploration\n",
        "# Display the first few rows of the dataset\n",
        "print(\"First few rows of the dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "# Display the dimensions of the dataset (number of rows and columns)\n",
        "print(\"\\nDataset dimensions:\")\n",
        "print(df.shape)\n",
        "\n",
        "# Check for missing values in the dataset\n",
        "print(\"\\nMissing values:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Step 3: Descriptive Statistics\n",
        "# Calculate basic statistics for the numerical columns\n",
        "print(\"\\nDescriptive statistics:\")\n",
        "print(df.describe())\n",
        "\n",
        "# Calculate the correlation matrix for the dataset\n",
        "print(\"\\nCorrelation matrix:\")\n",
        "print(df.corr())\n",
        "\n",
        "# Calculate the number of instances for each class in the 'outcome' column\n",
        "print(\"\\nClass distribution:\")\n",
        "print(df['outcome'].value_counts())\n",
        "\n",
        "# Calculate the percentage of each class in the 'outcome' column\n",
        "print(\"\\nClass distribution percentages:\")\n",
        "print(df['outcome'].value_counts(normalize=True) * 100)"
      ],
      "metadata": {
        "id": "q00xRPzJeGZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A quiz on Data Exploration and Descriptive Statistics"
      ],
      "metadata": {
        "id": "qpzFCK42O9M9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. Which Python library is commonly used for data manipulation and analysis?\n",
        "<br>a) Numpy\n",
        "<br>b) Pandas\n",
        "<br>c) Scikit-learn\n",
        "<br>d) Matplotlib\n",
        "\n",
        "2. What is the function used in Pandas to calculate summary statistics for a numerical column?\n",
        "<br>a) describe()\n",
        "<br>b) summary()\n",
        "<br>c) stats()\n",
        "<br>d) summary_stats()\n",
        "\n",
        "3. Which of the following is NOT a measure of central tendency?\n",
        "<br>a) Mean\n",
        "<br>b) Median\n",
        "<br>c) Mode\n",
        "<br>d) Variance\n",
        "\n",
        "4. How can you calculate the correlation matrix between columns in a Pandas DataFrame?\n",
        "<br>a) df.corr()\n",
        "<br>b) df.correlation()\n",
        "<br>c) df.calculate_correlation()\n",
        "<br>d) df.correlation_matrix()\n",
        "\n",
        "5. What function in Pandas allows you to group data based on one or more columns?\n",
        "<br>a) groupby()\n",
        "<br>b) split()\n",
        "<br>c) divide()\n",
        "<br>d) sort()\n",
        "\n",
        "6. Which aggregation function in Pandas calculates the maximum value in a group?\n",
        "<br>a) mean()\n",
        "<br>b) min()\n",
        "<br>c) max()\n",
        "<br>d) sum()\n",
        "\n",
        "7. Which method is used to create a scatter plot in Matplotlib?\n",
        "<br>a) plot()\n",
        "<br>b) scatter()\n",
        "<br>c) bar()\n",
        "<br>d) hist()\n",
        "\n",
        "8. How can you change the figure size in Matplotlib?\n",
        "<br>a) Using the `set_size()` method\n",
        "<br>b) Using the `resize()` method\n",
        "<br>c) Using the `figure_size()` method\n",
        "<br>d) Using the `figure()` function with the `figsize` parameter\n",
        "\n",
        "9. Which command in Matplotlib is used to add a title to a plot?\n",
        "<br>a) title()\n",
        "<br>b) add_title()\n",
        "<br>c) set_title()\n",
        "<br>d) plot_title()\n",
        "\n",
        "10. Which line of code can be used to display the plot created using Matplotlib?\n",
        "<br>a) `show()`\n",
        "<br>b) `display()`\n",
        "<br>c) `plot()`\n",
        "<br>d) `draw()`\n",
        "---\n",
        "Answers:\n",
        "\n",
        "1. b) Pandas\n",
        "2. a) describe()\n",
        "3. d) Variance\n",
        "4. a) df.corr()\n",
        "5. a) groupby()\n",
        "6. c) max()\n",
        "7. b) scatter()\n",
        "8. d) Using the `figure()` function with the `figsize` parameter\n",
        "9. c) set_title()\n",
        "10. a) `show()`\n",
        "---"
      ],
      "metadata": {
        "id": "ZG1-7VKNPAT6"
      }
    }
  ]
}