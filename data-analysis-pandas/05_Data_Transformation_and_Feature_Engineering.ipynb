{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOzkrbNaf+s8wppoT5A0cGM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cloudpedagogy/data-science-programming/blob/main/data-analysis-pandas/05_Data_Transformation_and_Feature_Engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Transformation and Feature Engineering\n"
      ],
      "metadata": {
        "id": "vbomx3cHYx00"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview"
      ],
      "metadata": {
        "id": "0kiWviQtXBSW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Data transformation and feature engineering are essential steps in data analysis and machine learning workflows. They involve manipulating and modifying data to make it more suitable for analysis or to create new features that can improve the performance of predictive models. Pandas, a popular data manipulation library in Python, provides a wide range of functions and methods to facilitate these tasks.\n",
        "\n",
        "Data transformation involves converting, cleaning, and reshaping data to make it more consistent and meaningful. It often involves tasks such as handling missing values, converting data types, removing duplicates, and normalizing or scaling variables. These transformations help to ensure data quality, improve the accuracy of analyses, and enhance the effectiveness of machine learning algorithms.\n",
        "\n",
        "Feature engineering, on the other hand, focuses on creating new features or extracting relevant information from existing ones. This process aims to capture the underlying patterns or relationships in the data that can improve model performance. Feature engineering techniques include creating interaction terms, binning or discretizing variables, encoding categorical variables, applying mathematical transformations, and deriving time-based features.\n",
        "\n",
        "Pandas provides a powerful set of tools to perform these data transformation and feature engineering tasks. It offers functions for handling missing data, reshaping and pivoting data, applying mathematical and statistical operations, merging and joining datasets, and much more. Additionally, pandas seamlessly integrates with other libraries commonly used in data analysis and machine learning, such as NumPy, scikit-learn, and matplotlib, allowing for a comprehensive and efficient workflow.\n",
        "\n",
        "In this context, understanding pandas' functionality and mastering its data transformation and feature engineering capabilities are crucial skills for data scientists and analysts. By effectively manipulating and engineering features, you can uncover hidden insights, reduce noise, and build more accurate predictive models, ultimately leading to better decision-making and business outcomes.\n",
        "\n"
      ],
      "metadata": {
        "id": "yikOD3peYgdS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Applying mathematical operations to columns\n"
      ],
      "metadata": {
        "id": "bd1fFTt3XOc4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "In Pandas, you can apply mathematical operations to columns using arithmetic operators or built-in mathematical functions. These operations allow you to perform calculations on specific columns and create new columns based on the results. Here's an example of applying mathematical operations to columns in the Pima Indian Diabetes dataset:\n"
      ],
      "metadata": {
        "id": "T5nENcSOZB0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the Pima Indian Diabetes dataset\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "column_names = [\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", \"Age\", \"Outcome\"]\n",
        "dataset = pd.read_csv(url, names=column_names)\n",
        "\n",
        "# Apply mathematical operations to columns\n",
        "dataset['BMI_squared'] = dataset['BMI'] ** 2\n",
        "dataset['Glucose_divided_by_Age'] = dataset['Glucose'] / dataset['Age']\n",
        "\n",
        "# Print the modified dataset\n",
        "print(dataset.head())\n"
      ],
      "metadata": {
        "id": "KvOEys_1ZGIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we load the Pima Indian Diabetes dataset using Pandas. We then apply two different mathematical operations to create new columns.\n",
        "\n",
        "1. The line `dataset['BMI_squared'] = dataset['BMI'] ** 2` squares the values in the 'BMI' column and assigns the result to a new column called 'BMI_squared'. This operation calculates the BMI squared for each record in the dataset.\n",
        "\n",
        "2. The line `dataset['Glucose_divided_by_Age'] = dataset['Glucose'] / dataset['Age']` divides the values in the 'Glucose' column by the values in the 'Age' column and assigns the result to a new column called 'Glucose_divided_by_Age'. This operation calculates the ratio of Glucose to Age for each record in the dataset.\n",
        "\n",
        "Finally, we print the modified dataset using `dataset.head()` to display the first few rows, including the newly created columns.\n"
      ],
      "metadata": {
        "id": "x8S6saYfZK9r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating new features from existing ones\n"
      ],
      "metadata": {
        "id": "abh7gtVrXTA7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating new features from existing ones in pandas allows you to extract additional information or combine existing features to enhance the predictive power of your dataset. These new features can capture relationships, patterns, or domain-specific insights that might not be apparent in the original features alone.\n",
        "\n",
        "Here's an example of creating a new feature from existing ones in the Pima Indian Diabetes dataset:\n"
      ],
      "metadata": {
        "id": "6xp7nlw6ZNkg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the Pima Indian Diabetes dataset\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "column_names = [\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", \"Age\", \"Outcome\"]\n",
        "dataset = pd.read_csv(url, names=column_names)\n",
        "\n",
        "# Create a new feature: BMI category\n",
        "dataset['BMI_Category'] = pd.cut(dataset['BMI'], bins=[0, 18.5, 24.9, 29.9, 100], labels=['Underweight', 'Normal', 'Overweight', 'Obese'])\n",
        "\n",
        "# Print the dataset with the new feature\n",
        "print(dataset.head())\n"
      ],
      "metadata": {
        "id": "TrEICYv9ZRc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we load the Pima Indian Diabetes dataset using Pandas. We then create a new feature called 'BMI_Category' by categorizing the 'BMI' feature into different BMI ranges. We use the `pd.cut()` function to define the bin intervals (0-18.5, 18.5-24.9, 24.9-29.9, 29.9-100) and assign corresponding labels ('Underweight', 'Normal', 'Overweight', 'Obese') to each category.\n",
        "\n",
        "The resulting dataset will have an additional column 'BMI_Category' that represents the BMI category for each record. This new feature provides a more categorical representation of BMI, which can be useful for analysis or modeling purposes.\n",
        "\n",
        "You can create new features by applying various transformations, combining columns, extracting information from text or dates, performing mathematical operations, or any other operation that derives meaningful information from existing features in your dataset.\n"
      ],
      "metadata": {
        "id": "0xz4BbAVZU-y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handling categorical variables using one-hot encoding\n"
      ],
      "metadata": {
        "id": "ozSARmi6XaNy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handling categorical variables, such as converting them into numerical values, is essential for many machine learning algorithms. One-hot encoding is a common technique used to convert categorical variables into binary vectors, where each category becomes a separate binary feature. This transformation allows the algorithm to interpret and utilize categorical data effectively.\n",
        "\n",
        "In Pandas, you can perform one-hot encoding using the `get_dummies()` function. This function converts categorical variables into dummy/indicator variables, creating new binary columns for each category. Here's an example of using one-hot encoding on the Pima Indian Diabetes dataset:\n"
      ],
      "metadata": {
        "id": "j78yAlBUZXrM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the Pima Indian Diabetes dataset\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "column_names = [\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", \"Age\", \"Outcome\"]\n",
        "dataset = pd.read_csv(url, names=column_names)\n",
        "\n",
        "# Select the categorical variable to encode\n",
        "categorical_variable = \"Outcome\"\n",
        "\n",
        "# Perform one-hot encoding\n",
        "encoded_dataset = pd.get_dummies(dataset, columns=[categorical_variable])\n",
        "\n",
        "# Print the encoded dataset\n",
        "print(encoded_dataset.head())\n"
      ],
      "metadata": {
        "id": "9KQa5up5ZcEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we load the Pima Indian Diabetes dataset using Pandas. We specify the categorical variable we want to encode, in this case, \"Outcome,\" which represents whether an individual has diabetes or not. We then apply the `get_dummies()` function on the dataset, passing the column name of the categorical variable to encode. The function creates new binary columns corresponding to each category and assigns a value of 1 if the category is present for that row and 0 otherwise. Finally, we print the encoded dataset using `encoded_dataset.head()` to display the first few rows.\n",
        "\n",
        "After one-hot encoding, the original categorical variable will be replaced by the binary columns representing each category. This allows the categorical information to be effectively utilized by machine learning algorithms that require numerical input.\n"
      ],
      "metadata": {
        "id": "m6-xeiRcZfpm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reflection Points"
      ],
      "metadata": {
        "id": "KiQZRowyZiAu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Applying mathematical operations to columns**:\n",
        "   - How can mathematical operations be applied to columns in a Pandas DataFrame?\n",
        "   - What are some commonly used mathematical operations (e.g., addition, subtraction, multiplication, division) and their corresponding methods or functions in Python?\n",
        "   - How can you perform mathematical operations on specific columns or groups of columns in a DataFrame?\n",
        "\n",
        "2. **Creating new features from existing ones**:\n",
        "   - Why is feature creation important in data analysis and machine learning?\n",
        "   - What are some techniques for creating new features based on existing ones?\n",
        "   - How can you use mathematical operations, string manipulation, or functions to generate new features?\n",
        "   - What considerations should be taken into account when creating new features, such as dealing with missing data or outliers?\n",
        "\n",
        "3. **Handling categorical variables using one-hot encoding**:\n",
        "   - What are categorical variables, and why do we need to handle them differently?\n",
        "   - How does one-hot encoding work, and why is it commonly used to encode categorical variables?\n",
        "   - What libraries and functions can you use in Python to perform one-hot encoding?\n",
        "   - How can you handle scenarios with a large number of categories or deal with new categories in test data?\n",
        "\n",
        "\n",
        "Answers to the Reflection Points:\n",
        "\n",
        "1. Example answers could include:\n",
        "   - Mathematical operations can be applied to columns using arithmetic operators (+, -, *, /) or built-in functions like `add()`, `subtract()`, `multiply()`, and `divide()`.\n",
        "   - You can perform operations on specific columns by accessing them using DataFrame indexing or by applying operations to groups of columns using functions like `apply()`.\n",
        "   \n",
        "2. Example answers could include:\n",
        "   - Feature creation allows you to extract more meaningful information or capture specific patterns from existing data.\n",
        "   - Techniques for creating new features include combining columns, transforming variables, deriving statistical aggregations, or applying domain-specific knowledge.\n",
        "   - Mathematical operations, string manipulation methods, or custom functions can be used to generate new features.\n",
        "\n",
        "3. Example answers could include:\n",
        "   - Categorical variables represent discrete values and need to be encoded numerically for machine learning algorithms to process them.\n",
        "   - One-hot encoding converts categorical variables into binary columns, representing the presence or absence of each category.\n",
        "   - Libraries like pandas provide functions such as `get_dummies()` or `OneHotEncoder` from scikit-learn can be used for one-hot encoding.\n",
        "   - Considerations include handling missing values or handling categories that are not present in the training data.\n"
      ],
      "metadata": {
        "id": "V2FQLnqakOu6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise"
      ],
      "metadata": {
        "id": "EPOXMb0yfcFX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. Load the dataset from the provided URL.\n",
        "2. Explore the dataset to understand its structure and statistics.\n",
        "3. Handle any missing values in the dataset.\n",
        "4. Perform feature engineering by adding new relevant features (e.g., age groups, BMI category, etc.).\n",
        "5. Encode categorical variables (if any) into numerical format.\n",
        "6. Normalize or scale numerical features if required.\n",
        "7. Save the preprocessed data to a new CSV file.\n",
        "\n"
      ],
      "metadata": {
        "id": "w0aU4RyWffop"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sample Solution"
      ],
      "metadata": {
        "id": "170_8BSafzGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "columns = ['pregnancies', 'glucose', 'blood_pressure', 'skin_thickness', 'insulin', 'bmi', 'diabetes_pedigree', 'age', 'outcome']\n",
        "df = pd.read_csv(url, names=columns)\n",
        "\n",
        "# Step 2: Explore the dataset\n",
        "print(df.head())       # Display the first few rows\n",
        "print(df.info())       # Overview of data types and missing values\n",
        "print(df.describe())   # Statistical summary of the dataset\n",
        "\n",
        "# Step 3: Handle missing values (if any)\n",
        "# For this exercise, assume there are no missing values in the dataset.\n",
        "# If there were missing values, you could use df.fillna() or df.dropna() to handle them.\n",
        "\n",
        "# Step 4: Feature engineering\n",
        "# Example: Create age groups based on age\n",
        "age_bins = [0, 25, 40, 60, float('inf')]\n",
        "age_labels = ['young', 'young-adult', 'adult', 'senior']\n",
        "df['age_group'] = pd.cut(df['age'], bins=age_bins, labels=age_labels)\n",
        "\n",
        "# Example: Categorize BMI into three categories\n",
        "bmi_bins = [0, 18.5, 24.9, float('inf')]\n",
        "bmi_labels = ['underweight', 'normal', 'overweight']\n",
        "df['bmi_category'] = pd.cut(df['bmi'], bins=bmi_bins, labels=bmi_labels)\n",
        "\n",
        "# Step 5: Encode categorical variables (if any)\n",
        "# For this dataset, there are no categorical variables to encode.\n",
        "# If there were categorical variables, you could use pd.get_dummies() or other encoding methods.\n",
        "\n",
        "# Step 6: Normalize or scale numerical features (if required)\n",
        "# For this exercise, assume that the numerical features are already in an appropriate scale.\n",
        "# If required, you can use techniques like Min-Max Scaling or Standard Scaling.\n",
        "\n",
        "# Step 7: Save the preprocessed data to a new CSV file\n",
        "df.to_csv('pima_indian_preprocessed.csv', index=False)\n",
        "\n",
        "print(\"Preprocessing and Feature Engineering Completed!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POegbiPKgLpe",
        "outputId": "15bc3b47-a8ef-4f9c-e8f9-727e8934b97e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   pregnancies  glucose  blood_pressure  skin_thickness  insulin   bmi  \\\n",
            "0            6      148              72              35        0  33.6   \n",
            "1            1       85              66              29        0  26.6   \n",
            "2            8      183              64               0        0  23.3   \n",
            "3            1       89              66              23       94  28.1   \n",
            "4            0      137              40              35      168  43.1   \n",
            "\n",
            "   diabetes_pedigree  age  outcome  \n",
            "0              0.627   50        1  \n",
            "1              0.351   31        0  \n",
            "2              0.672   32        1  \n",
            "3              0.167   21        0  \n",
            "4              2.288   33        1  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 768 entries, 0 to 767\n",
            "Data columns (total 9 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   pregnancies        768 non-null    int64  \n",
            " 1   glucose            768 non-null    int64  \n",
            " 2   blood_pressure     768 non-null    int64  \n",
            " 3   skin_thickness     768 non-null    int64  \n",
            " 4   insulin            768 non-null    int64  \n",
            " 5   bmi                768 non-null    float64\n",
            " 6   diabetes_pedigree  768 non-null    float64\n",
            " 7   age                768 non-null    int64  \n",
            " 8   outcome            768 non-null    int64  \n",
            "dtypes: float64(2), int64(7)\n",
            "memory usage: 54.1 KB\n",
            "None\n",
            "       pregnancies     glucose  blood_pressure  skin_thickness     insulin  \\\n",
            "count   768.000000  768.000000      768.000000      768.000000  768.000000   \n",
            "mean      3.845052  120.894531       69.105469       20.536458   79.799479   \n",
            "std       3.369578   31.972618       19.355807       15.952218  115.244002   \n",
            "min       0.000000    0.000000        0.000000        0.000000    0.000000   \n",
            "25%       1.000000   99.000000       62.000000        0.000000    0.000000   \n",
            "50%       3.000000  117.000000       72.000000       23.000000   30.500000   \n",
            "75%       6.000000  140.250000       80.000000       32.000000  127.250000   \n",
            "max      17.000000  199.000000      122.000000       99.000000  846.000000   \n",
            "\n",
            "              bmi  diabetes_pedigree         age     outcome  \n",
            "count  768.000000         768.000000  768.000000  768.000000  \n",
            "mean    31.992578           0.471876   33.240885    0.348958  \n",
            "std      7.884160           0.331329   11.760232    0.476951  \n",
            "min      0.000000           0.078000   21.000000    0.000000  \n",
            "25%     27.300000           0.243750   24.000000    0.000000  \n",
            "50%     32.000000           0.372500   29.000000    0.000000  \n",
            "75%     36.600000           0.626250   41.000000    1.000000  \n",
            "max     67.100000           2.420000   81.000000    1.000000  \n",
            "Preprocessing and Feature Engineering Completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A quiz on Data Transformation and Feature Engineering"
      ],
      "metadata": {
        "id": "A3rHNTVOYrki"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. Which pandas function is used to apply a mathematical operation to a column?\n",
        "<br>a) apply()\n",
        "<br>b) map()\n",
        "<br>c) transform()\n",
        "<br>d) operate()\n",
        "\n",
        "2. What does the following line of code do?\n",
        "   df['new_column'] = df['column1'] + df['column2']\n",
        "<br>a) Creates a new column in the DataFrame with the sum of 'column1' and 'column2'\n",
        "<br>b) Multiplies 'column1' and 'column2' and assigns the result to a new column\n",
        "<br>c) Subtracts 'column2' from 'column1' and assigns the result to a new column\n",
        "<br>d) Raises an error because mathematical operations cannot be applied directly to columns in pandas\n",
        "\n",
        "3. How can you create a new feature in a pandas DataFrame by combining existing features?\n",
        "<br>a) By using the merge() function\n",
        "<br>b) By using the concat() function\n",
        "<br>c) By using the add() function\n",
        "<br>d) By using the assign() function\n",
        "\n",
        "4. Which pandas function is used to handle categorical variables by converting them into one-hot encoded columns?\n",
        "<br>a) get_dummies()\n",
        "<br>b) one_hot_encode()\n",
        "<br>c) categorical_encode()\n",
        "<br>d) encode_categorical()\n",
        "\n",
        "5. What is the purpose of one-hot encoding categorical variables?\n",
        "<br>a) To convert categorical variables into numerical values\n",
        "<br>b) To reduce the dimensionality of the dataset\n",
        "<br>c) To make the data more visually appealing\n",
        "<br>d) To perform mathematical operations on categorical variables\n",
        "\n",
        "---\n",
        "Answers:\n",
        "\n",
        "1. a) apply()\n",
        "2. a) Creates a new column in the DataFrame with the sum of 'column1' and 'column2'\n",
        "3. d) By using the assign() function\n",
        "4. a) get_dummies()\n",
        "5. a) To convert categorical variables into numerical values\n",
        "---"
      ],
      "metadata": {
        "id": "m_6thSLWaKHy"
      }
    }
  ]
}