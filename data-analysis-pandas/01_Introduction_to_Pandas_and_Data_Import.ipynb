{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP66g+6xA+o5Be4itrzjVXn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cloudpedagogy/data-science-programming/blob/main/data-analysis-pandas/01_Introduction_to_Pandas_and_Data_Import.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Introduction to Pandas and its features\n"
      ],
      "metadata": {
        "id": "8GxI2npMSFlF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Overview\n",
        "\n",
        "Pandas is a popular open-source library in Python used for data manipulation, analysis, and cleaning. It provides easy-to-use data structures and data analysis tools, making it a powerful tool for working with structured data. Here's an introduction to some of the key features of Pandas:\n",
        "\n",
        "1. Data Structures:\n",
        "   Pandas provides two primary data structures: Series and DataFrame.\n",
        "   - Series: It represents a one-dimensional labeled array that can hold any data type. It is similar to a column in a spreadsheet or a single column of data in a NumPy array.\n",
        "   - DataFrame: It is a two-dimensional labeled data structure that consists of columns, where each column can have a different data type. It is similar to a spreadsheet or a SQL table, and it is the most commonly used data structure in Pandas.\n",
        "\n",
        "2. Data Manipulation:\n",
        "   Pandas offers a wide range of functions for data manipulation, including:\n",
        "   - Reading and writing data: Pandas supports reading data from various file formats, such as CSV, Excel, SQL databases, and more. It also provides functions to write data to these formats.\n",
        "   - Selection and filtering: Pandas allows selecting and filtering data based on specific criteria using indexing, boolean operations, or conditional statements.\n",
        "   - Joining and merging: Pandas provides functions to combine multiple DataFrames based on common columns or indices.\n",
        "   - Grouping and aggregation: Pandas allows grouping data based on one or more variables and applying aggregate functions, such as sum, mean, count, etc.\n",
        "   - Handling missing data: Pandas provides functions to handle missing or null values in data, such as dropping missing values or filling them with appropriate values.\n",
        "\n",
        "3. Data Analysis:\n",
        "   Pandas offers powerful tools for data analysis, including:\n",
        "   - Descriptive statistics: Pandas provides functions to calculate various summary statistics, such as mean, median, standard deviation, etc., for numerical columns.\n",
        "   - Data visualization: Pandas integrates well with other libraries, such as Matplotlib and Seaborn, to create visualizations such as line plots, scatter plots, histograms, etc.\n",
        "   - Time series analysis: Pandas has extensive support for handling time series data, including date/time indexing, resampling, rolling windows, and more.\n",
        "\n",
        "4. Performance and Efficiency:\n",
        "   Pandas is designed for efficient data handling and processing. It uses optimized data structures and algorithms, such as vectorized operations, to perform computations on large datasets efficiently. Additionally, Pandas integrates well with other libraries, such as NumPy and Scikit-learn, for enhanced performance and compatibility.\n",
        "\n",
        "These are just a few of the many features offered by Pandas. It is widely used in various domains, including data analysis, machine learning, finance, and more. Its versatility and ease of use make it a valuable tool for working with structured data in Python.\n"
      ],
      "metadata": {
        "id": "LmwNJ8AWSJte"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading data from CSV file"
      ],
      "metadata": {
        "id": "i9hBRNLdGG4X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading data from CSV file (Pima Indian Diabetes dataset) using Pandas**\n",
        "\n",
        "To load data from a CSV file, such as the Pima Indian Diabetes dataset, using Pandas, you can use the `read_csv()` function. Here's an example:\n"
      ],
      "metadata": {
        "id": "hbyhgCgmSOF_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Specify the path or URL of the CSV file\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "\n",
        "# Define column names for the dataset\n",
        "column_names = [\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", \"Age\", \"Outcome\"]\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "dataset = pd.read_csv(url, names=column_names)\n",
        "\n",
        "# Print the first few rows of the dataset\n",
        "print(dataset.head())\n"
      ],
      "metadata": {
        "id": "4B9S1g3HSU21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we use the `read_csv()` function from Pandas to load the CSV file. The `url` variable contains the path or URL of the CSV file. You can also use a local file path if the CSV file is stored on your machine.\n",
        "\n",
        "We define `column_names` to specify the names of the columns in the dataset. The `names` parameter in the `read_csv()` function allows us to provide these column names.\n",
        "\n",
        "Then, we use `pd.read_csv(url, names=column_names)` to load the CSV file into a DataFrame called `dataset`. The `read_csv()` function reads the file and creates a DataFrame object with the provided column names.\n",
        "\n",
        "Finally, we print the first few rows of the dataset using the `head()` function to verify that the data has been loaded correctly.\n"
      ],
      "metadata": {
        "id": "07eGEojWSZez"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exploring the dataset structure"
      ],
      "metadata": {
        "id": "9JVvGIk0GYXB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exploring the dataset structure and basic data manipulation operations**\n",
        "\n",
        "Certainly! The Pima Indian Diabetes dataset is commonly used for classification tasks, particularly for predicting whether or not a patient has diabetes based on various health measurements. Let's explore the dataset structure and perform some basic data manipulation operations using this dataset.\n"
      ],
      "metadata": {
        "id": "uW3alaR4Scud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the Pima Indian Diabetes dataset\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "column_names = [\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", \"Age\", \"Outcome\"]\n",
        "dataset = pd.read_csv(url, names=column_names)\n",
        "\n",
        "# Display the first few records in the dataset\n",
        "print(dataset.head())\n",
        "\n",
        "# Get the shape of the dataset\n",
        "print(\"Dataset shape:\", dataset.shape)\n",
        "\n",
        "# Check the data types of the columns\n",
        "print(\"Data types of columns:\\n\", dataset.dtypes)\n",
        "\n",
        "# Check the summary statistics of the dataset\n",
        "print(\"Summary statistics:\\n\", dataset.describe())\n",
        "\n",
        "# Count the number of missing values in each column\n",
        "print(\"Number of missing values:\\n\", dataset.isnull().sum())\n",
        "\n",
        "# Count the number of records for each outcome class\n",
        "print(\"Number of records for each outcome class:\\n\", dataset['Outcome'].value_counts())\n",
        "\n",
        "# Filter the dataset to select records with diabetes outcome\n",
        "diabetes_records = dataset[dataset['Outcome'] == 1]\n",
        "\n",
        "# Calculate the average age of patients with diabetes\n",
        "average_age_diabetes = diabetes_records['Age'].mean()\n",
        "print(\"Average age of patients with diabetes:\", average_age_diabetes)\n"
      ],
      "metadata": {
        "id": "Boo0J13oSghb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we use the Pandas library to load and manipulate the Pima Indian Diabetes dataset.\n",
        "\n",
        "First, we load the dataset from the provided URL and assign column names to it. We then display the first few records in the dataset using the `head()` method.\n",
        "\n",
        "Next, we use various operations to gather information about the dataset. We retrieve the shape of the dataset using the `shape` attribute, which provides the number of rows and columns. The `dtypes` attribute displays the data types of each column.\n",
        "\n",
        "To get a sense of the data distribution, we use the `describe()` method to calculate summary statistics such as count, mean, standard deviation, minimum, and maximum values for each column.\n",
        "\n",
        "We also check for missing values in the dataset by using the `isnull().sum()` operation, which sums up the number of missing values in each column.\n",
        "\n",
        "Furthermore, we count the number of records for each outcome class using the `value_counts()` method on the 'Outcome' column.\n",
        "\n",
        "To perform more specific data manipulation, we filter the dataset to select only the records where the 'Outcome' column is equal to 1 (indicating diabetes). This creates a new DataFrame called `diabetes_records`.\n",
        "\n",
        "Finally, we calculate the average age of patients with diabetes by using the `mean()` method on the 'Age' column of the `diabetes_records` DataFrame.\n",
        "\n",
        "These operations provide a starting point for exploring and manipulating the Pima Indian Diabetes dataset, allowing you to gain insights and perform further analysis.\n"
      ],
      "metadata": {
        "id": "_3fBkXuDSk3C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reflection points"
      ],
      "metadata": {
        "id": "h0JVHXQNSoXh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **What is Pandas and why is it widely used in data analysis?**\n",
        "   - Pandas is a powerful Python library that provides data manipulation and analysis tools. It is widely used due to its ability to handle structured data efficiently, its flexibility in data manipulation operations, and its integration with other data analysis libraries.\n",
        "\n",
        "2. **How do you install Pandas and its necessary dependencies?**\n",
        "   - Pandas can be installed using Python's package manager, pip. Open a command prompt or terminal and run the command: `pip install pandas`. This will install Pandas and its necessary dependencies automatically.\n",
        "\n",
        "3. **How do you load data from a CSV file using Pandas?**\n",
        "   - To load data from a CSV file using Pandas, you can use the `read_csv()` function. It takes the file path as input and returns a DataFrame object containing the data. Example: `import pandas as pd` and `df = pd.read_csv('filename.csv')`.\n",
        "\n",
        "4. **What are some common methods to explore the structure of a DataFrame?**\n",
        "   - The `head()`, `tail()`, and `info()` methods are commonly used to explore the structure of a DataFrame. `head()` displays the first few rows, `tail()` displays the last few rows, and `info()` provides information about the columns, data types, and missing values.\n",
        "\n",
        "5. **How can you access specific columns or rows in a DataFrame?**\n",
        "   - To access specific columns in a DataFrame, you can use square brackets or the dot notation. For example, `df['column_name']` or `df.column_name`. To access specific rows, you can use the `iloc` or `loc` indexer. Example: `df.iloc[0]` to access the first row.\n",
        "\n",
        "6. **How do you perform basic data manipulation operations on a DataFrame?**\n",
        "   - Data manipulation operations on a DataFrame include selecting specific columns, filtering rows based on conditions, adding or removing columns, and performing calculations on columns. Pandas provides functions and methods such as `loc[]`, `iloc[]`, `filter()`, `drop()`, and mathematical operators to perform these operations.\n",
        "\n",
        "7. **How can you handle missing values in a DataFrame?**\n",
        "   - Pandas provides methods such as `isna()`, `fillna()`, and `dropna()` to handle missing values in a DataFrame. `isna()` helps identify missing values, `fillna()` fills the missing values with specified values or strategies, and `dropna()` removes rows or columns containing missing values.\n"
      ],
      "metadata": {
        "id": "BT6Iu5MUiesq"
      }
    }
  ]
}
