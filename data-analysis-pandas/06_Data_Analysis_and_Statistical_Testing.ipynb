{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPWclY3ExPS+LmZLewBKwVy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cloudpedagogy/data-science-programming/blob/main/data-analysis-pandas/06_Data_Analysis_and_Statistical_Testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Analysis and Statistical Testing\n"
      ],
      "metadata": {
        "id": "A22Ay8D8ZuG1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Overview"
      ],
      "metadata": {
        "id": "5j5ss4nBbohz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Data analysis is a crucial aspect of extracting meaningful insights and making informed decisions in various fields, including business, research, and data science. Pandas, a popular data manipulation library in Python, provides powerful tools for data analysis and statistical testing. With its intuitive syntax and extensive functionality, pandas enables users to effectively analyze, manipulate, and visualize datasets.\n",
        "\n",
        "Pandas offers a wide range of data structures, such as Series and DataFrame, which allow for efficient handling of structured data. Series represents a one-dimensional array-like object, while DataFrame is a two-dimensional tabular data structure that organizes data into rows and columns. These structures provide a foundation for performing various data analysis tasks.\n",
        "\n",
        "Statistical testing, often referred to as hypothesis testing, is an essential component of data analysis. It allows us to evaluate hypotheses and draw conclusions based on data. Pandas integrates seamlessly with other statistical libraries, such as NumPy and SciPy, to provide a comprehensive environment for conducting statistical testing.\n",
        "\n",
        "Using pandas, you can perform various statistical operations, such as descriptive statistics, correlation analysis, and hypothesis testing. Descriptive statistics summarize the main characteristics of a dataset, including measures of central tendency (mean, median) and dispersion (standard deviation, variance). Pandas offers convenient functions like `mean()`, `median()`, `std()`, and `describe()` to calculate and display these statistics.\n",
        "\n",
        "Correlation analysis helps identify relationships between variables. Pandas provides methods like `corr()` and `cov()` to compute correlation coefficients and covariance, respectively. These measures help assess the strength and direction of relationships between different variables in the dataset.\n",
        "\n",
        "Statistical testing involves making inferences about populations based on sample data. Pandas, in conjunction with statistical libraries like SciPy, offers functions for conducting hypothesis tests. These tests include t-tests, chi-square tests, ANOVA (analysis of variance), and more. These tools enable you to analyze and draw conclusions about the significance of observed differences or relationships in the data.\n",
        "\n"
      ],
      "metadata": {
        "id": "eH-p7Jenbrhy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Performing statistical analysis on the dataset\n"
      ],
      "metadata": {
        "id": "DGFZGePtbwtJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performing statistical analysis on a dataset using Pandas allows you to gain insights into the data, such as calculating descriptive statistics, correlation between variables, and more. Pandas provides several functions for statistical analysis. Here's an example using the Pima Indian Diabetes dataset:\n"
      ],
      "metadata": {
        "id": "jMqJCnvtZw7i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the Pima Indian Diabetes dataset\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "column_names = [\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", \"Age\", \"Outcome\"]\n",
        "dataset = pd.read_csv(url, names=column_names)\n",
        "\n",
        "# Calculate descriptive statistics\n",
        "statistics = dataset.describe()\n",
        "print(\"Descriptive Statistics:\")\n",
        "print(statistics)\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "correlation_matrix = dataset.corr()\n",
        "print(\"\\nCorrelation Matrix:\")\n",
        "print(correlation_matrix)\n"
      ],
      "metadata": {
        "id": "f2qJRtxyZ0UT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we load the Pima Indian Diabetes dataset using Pandas. We then use two common statistical analysis functions:\n",
        "\n",
        "1. `describe()`: This function calculates various descriptive statistics for each column in the dataset, such as count, mean, standard deviation, minimum, 25th percentile, median (50th percentile), 75th percentile, and maximum. We store the result in the `statistics` variable and print it to see the output.\n",
        "\n",
        "2. `corr()`: This function calculates the pairwise correlation between columns in the dataset, using the default Pearson correlation coefficient. The result is a correlation matrix that shows how each variable is related to others. We store the result in the `correlation_matrix` variable and print it to see the output.\n",
        "\n",
        "These statistical analysis techniques provide valuable information about the dataset, such as the central tendency, variability, and relationships between variables.\n"
      ],
      "metadata": {
        "id": "tW8oLizWZ8R-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hypothesis testing and p-values\n"
      ],
      "metadata": {
        "id": "HmAGveEnb2Uc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Hypothesis testing is a statistical method used to make inferences or draw conclusions about a population based on sample data. It involves formulating a null hypothesis (H0) and an alternative hypothesis (H1), and then using statistical tests to determine the likelihood of observing the sample data if the null hypothesis is true. The p-value is a measure of the strength of evidence against the null hypothesis.\n",
        "\n",
        "In Pandas, you can perform hypothesis testing and calculate p-values using various statistical tests available in libraries such as SciPy or StatsModels. One commonly used test is the t-test, which is used to compare the means of two groups.\n",
        "\n",
        "Here's an example of hypothesis testing using a t-test and calculating p-values on the Pima Indian Diabetes dataset:\n"
      ],
      "metadata": {
        "id": "wclfJx7OZ_HB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy import stats\n",
        "\n",
        "# Load the Pima Indian Diabetes dataset\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "column_names = [\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", \"Age\", \"Outcome\"]\n",
        "dataset = pd.read_csv(url, names=column_names)\n",
        "\n",
        "# Separate the data into two groups based on the outcome\n",
        "group1 = dataset[dataset['Outcome'] == 0]\n",
        "group2 = dataset[dataset['Outcome'] == 1]\n",
        "\n",
        "# Perform a t-test between the two groups for the 'Glucose' feature\n",
        "t_statistic, p_value = stats.ttest_ind(group1['Glucose'], group2['Glucose'], equal_var=False)\n",
        "\n",
        "# Print the t-statistic and p-value\n",
        "print(\"T-Statistic:\", t_statistic)\n",
        "print(\"P-Value:\", p_value)\n"
      ],
      "metadata": {
        "id": "-eI_93BraC1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we load the Pima Indian Diabetes dataset using Pandas. We separate the data into two groups based on the 'Outcome' column, where group1 represents individuals without diabetes (Outcome=0) and group2 represents individuals with diabetes (Outcome=1). We then perform an independent t-test using the `ttest_ind()` function from the SciPy library to compare the 'Glucose' levels between the two groups. The `equal_var=False` parameter is used to indicate that the variances of the two groups are not assumed to be equal. The t-statistic and p-value are calculated and stored in the variables `t_statistic` and `p_value`, respectively. Finally, we print the t-statistic and p-value to evaluate the significance of the difference in 'Glucose' levels between the two groups."
      ],
      "metadata": {
        "id": "lJORIVm-aH3N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Correlation and covariance analysis\n"
      ],
      "metadata": {
        "id": "cvqK1IM0b_aJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Correlation\n"
      ],
      "metadata": {
        "id": "3rq_ToYgcIaE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Correlation analysis in Pandas involves calculating the statistical relationship between variables using correlation coefficients. The correlation coefficient measures the strength and direction of the linear relationship between two variables. It ranges from -1 to +1, where -1 indicates a strong negative correlation, +1 indicates a strong positive correlation, and 0 indicates no correlation.\n",
        "\n",
        "In Pandas, you can use the `corr()` function to calculate the correlation matrix between multiple variables in a DataFrame. Here's an example of performing correlation analysis on the Pima Indian Diabetes dataset:\n"
      ],
      "metadata": {
        "id": "YNt_SzCjaKz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the Pima Indian Diabetes dataset\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "column_names = [\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", \"Age\", \"Outcome\"]\n",
        "dataset = pd.read_csv(url, names=column_names)\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "correlation_matrix = dataset.corr()\n",
        "\n",
        "# Print the correlation matrix\n",
        "print(correlation_matrix)\n"
      ],
      "metadata": {
        "id": "7vP1CwnnaO2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we load the Pima Indian Diabetes dataset using Pandas. We then use the `corr()` function on the dataset to calculate the correlation matrix. The resulting correlation matrix will show the pairwise correlations between all variables in the dataset. Finally, we print the correlation matrix to see the output.\n",
        "\n",
        "The correlation matrix will have a size of n x n, where n is the number of variables. The diagonal elements will always be 1 since a variable is perfectly correlated with itself. The off-diagonal elements represent the correlation coefficients between different variables. Positive values indicate a positive correlation, negative values indicate a negative correlation, and values close to 0 indicate little to no correlation.\n",
        "\n",
        "Correlation analysis helps identify relationships between variables and can be useful for feature selection, identifying multicollinearity, and understanding the impact of variables on the target variable in predictive modeling tasks.\n"
      ],
      "metadata": {
        "id": "B08_2L4caTgW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Covariance analysis\n"
      ],
      "metadata": {
        "id": "NdB5Sul4cKSC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Covariance analysis, also known as covariance matrix analysis, is a statistical technique used to analyze the relationship between multiple variables. It measures the degree to which two variables vary together. In Pandas, you can compute the covariance matrix using the `cov()` function.\n",
        "\n",
        "Here's an example of covariance analysis on the Pima Indian Diabetes dataset:\n"
      ],
      "metadata": {
        "id": "-9vTd9UGacBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the Pima Indian Diabetes dataset\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "column_names = [\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", \"Age\", \"Outcome\"]\n",
        "dataset = pd.read_csv(url, names=column_names)\n",
        "\n",
        "# Select the features for covariance analysis\n",
        "features = [\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", \"Age\"]\n",
        "\n",
        "# Compute the covariance matrix\n",
        "covariance_matrix = dataset[features].cov()\n",
        "\n",
        "# Print the covariance matrix\n",
        "print(covariance_matrix)\n"
      ],
      "metadata": {
        "id": "JpXq_w7mawjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we load the Pima Indian Diabetes dataset using Pandas. We specify the features we want to include in the covariance analysis, which are \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", and \"Age\". We then use the `cov()` function to compute the covariance matrix for these features. The resulting `covariance_matrix` will show the pairwise covariance values between the selected features.\n",
        "\n",
        "By examining the covariance matrix, you can gain insights into the relationships and dependencies between different variables. Positive values indicate a positive relationship, negative values indicate a negative relationship, and values close to zero indicate a weak or no relationship.\n",
        "\n",
        "Note: Covariance analysis provides information about the linear relationship between variables. It is important to interpret the results carefully and consider other factors such as correlation coefficients and domain knowledge to draw meaningful conclusions from the covariance matrix.\n"
      ],
      "metadata": {
        "id": "kvKjA6OZa6sB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data aggregation and cross-tabulation\n"
      ],
      "metadata": {
        "id": "S2F2Kdu5cOK_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data aggregation\n"
      ],
      "metadata": {
        "id": "RfZv34A9cSX4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "Data aggregation in pandas involves combining and summarizing data based on certain criteria. It allows you to calculate various statistics, such as mean, sum, count, maximum, minimum, etc., for specific groups or subsets of data. Aggregation is helpful for gaining insights into the data and understanding patterns and trends.\n",
        "\n",
        "Here's an example of data aggregation on the Pima Indian Diabetes dataset using pandas:\n"
      ],
      "metadata": {
        "id": "vq3b4NdWa-Nr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the Pima Indian Diabetes dataset\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "column_names = [\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", \"Age\", \"Outcome\"]\n",
        "dataset = pd.read_csv(url, names=column_names)\n",
        "\n",
        "# Group the data by the 'Outcome' column and calculate the mean of other numeric columns\n",
        "grouped_data = dataset.groupby('Outcome').mean()\n",
        "\n",
        "# Print the aggregated data\n",
        "print(grouped_data)\n"
      ],
      "metadata": {
        "id": "CUm3DYD2bFbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we load the Pima Indian Diabetes dataset using Pandas. We then use the `groupby()` function to group the data based on the 'Outcome' column, which indicates whether a person has diabetes or not (0: non-diabetic, 1: diabetic). We calculate the mean of the other numeric columns for each group using the `mean()` function.\n",
        "\n",
        "The resulting `grouped_data` DataFrame will have two rows, one for each outcome group (0 and 1), and the columns will represent the mean values for each numeric feature within each group. This aggregation provides insights into the average values of different features for diabetic and non-diabetic individuals.\n",
        "\n",
        "You can customize the aggregation by using different aggregation functions (e.g., `sum()`, `count()`, `max()`, `min()`, etc.) or applying multiple aggregations to different columns simultaneously.\n"
      ],
      "metadata": {
        "id": "yn8IFUN8bJdn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Cross-tabulation\n"
      ],
      "metadata": {
        "id": "R6CPVaYPcYO2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Cross-tabulation, also known as a contingency table, is a way to summarize and analyze the relationship between two or more categorical variables. It provides a tabular representation that shows the frequency or count of observations for different combinations of variables. Pandas provides a convenient function, `pd.crosstab()`, to perform cross-tabulation.\n",
        "\n",
        "Here's an example of performing cross-tabulation on the Pima Indian Diabetes dataset:\n"
      ],
      "metadata": {
        "id": "tFlsHs_mbMEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the Pima Indian Diabetes dataset\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "column_names = [\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", \"Age\", \"Outcome\"]\n",
        "dataset = pd.read_csv(url, names=column_names)\n",
        "\n",
        "# Perform cross-tabulation on the 'Age' and 'Outcome' variables\n",
        "cross_tab = pd.crosstab(dataset['Age'], dataset['Outcome'])\n",
        "\n",
        "# Print the cross-tabulation table\n",
        "print(cross_tab)\n"
      ],
      "metadata": {
        "id": "5DN2hPf5bQAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we load the Pima Indian Diabetes dataset using Pandas. We then use the `pd.crosstab()` function to perform cross-tabulation on two variables: 'Age' and 'Outcome'. The resulting `cross_tab` table shows the frequency of different outcomes (0 or 1) for different age values. Each row represents a different age value, and each column represents a different outcome value. The values in the table indicate the count of observations for each combination of age and outcome.\n",
        "\n",
        "By using cross-tabulation, you can gain insights into how different variables are related and analyze patterns or dependencies between them.\n"
      ],
      "metadata": {
        "id": "aSmib7X6bXnP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reflection points"
      ],
      "metadata": {
        "id": "Dv_U50eGbbBM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Performing statistical analysis on the dataset**:\n",
        "   - Reflect on the importance of statistical analysis in understanding and interpreting data.\n",
        "   - Consider how different statistical measures (e.g., mean, median, standard deviation) provide insights into data distribution and central tendencies.\n",
        "   - Discuss the significance of visualizations (e.g., histograms, box plots) in exploring data patterns and outliers.\n",
        "\n",
        "Sample Answer: Statistical analysis helps us make sense of data by summarizing and interpreting key features. Measures like the mean and standard deviation give us an understanding of central tendencies and dispersion. Visualizations provide a way to explore data visually, allowing us to identify patterns, trends, and anomalies.\n",
        "\n",
        "2. **Hypothesis testing and p-values**:\n",
        "   - Reflect on the purpose and process of hypothesis testing in statistical analysis.\n",
        "   - Consider the concept of null and alternative hypotheses and their implications.\n",
        "   - Discuss the significance of p-values in hypothesis testing and how they indicate the strength of evidence against the null hypothesis.\n",
        "\n",
        "Sample Answer: Hypothesis testing allows us to make inferences about population characteristics based on sample data. The null hypothesis represents the assumption we want to test, while the alternative hypothesis suggests a different outcome. The p-value measures the strength of evidence against the null hypothesis, and a smaller p-value suggests stronger evidence to reject the null hypothesis in favor of the alternative.\n",
        "\n",
        "3. **Correlation and covariance analysis**:\n",
        "   - Reflect on the concept of correlation and its significance in understanding relationships between variables.\n",
        "   - Consider the difference between correlation and causation.\n",
        "   - Discuss the importance of covariance analysis in examining the relationship and variability between two or more variables.\n",
        "\n",
        "Sample Answer: Correlation measures the strength and direction of the linear relationship between two variables. It helps us understand how changes in one variable relate to changes in another. It's important to remember that correlation does not imply causation. Covariance analysis provides insights into the relationship and variability between variables, helping us understand their joint behavior and potential dependencies.\n",
        "\n",
        "4. **Data aggregation and cross-tabulation**:\n",
        "   - Reflect on the process of aggregating data and its benefits in summarizing large datasets.\n",
        "   - Consider different methods of data aggregation, such as grouping, averaging, or summing.\n",
        "   - Discuss the significance of cross-tabulation in analyzing categorical variables and identifying relationships between them.\n",
        "\n",
        "Sample Answer: Data aggregation involves combining and summarizing data to obtain meaningful insights. Aggregating data allows us to analyze trends, patterns, and summaries at higher levels. Cross-tabulation, also known as contingency table analysis, helps us understand the relationship between categorical variables by examining their joint frequencies. It enables us to identify associations or dependencies between different categories.\n"
      ],
      "metadata": {
        "id": "crFAN6h8bgRX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#A quiz on Data Analysis and Statistical Testing"
      ],
      "metadata": {
        "id": "m1iF275KdrkW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. Which library in Python is commonly used for data manipulation and analysis?\n",
        "   <br>a) NumPy\n",
        "   <br>b) Pandas\n",
        "   <br>c) Matplotlib\n",
        "   <br>d) Scikit-learn\n",
        "\n",
        "2. What is the function used in pandas to load a dataset from a CSV file?\n",
        "   <br>a) read_csv()\n",
        "   <br>b) load_csv()\n",
        "   <br>c) import_csv()\n",
        "   <br>d) open_csv()\n",
        "\n",
        "3. How do you calculate the mean of a column in a pandas DataFrame?\n",
        "   <br>a) df.mean()\n",
        "   <br>b) df.calculate_mean()\n",
        "   <br>c) df.column_mean()\n",
        "   <br>d) df.get_mean()\n",
        "\n",
        "4. What is hypothesis testing used for?\n",
        "   <br>a) Analyzing the correlation between variables\n",
        "   <br>b) Aggregating data and cross-tabulation\n",
        "   <br>c) Testing a claim or assumption about a population parameter\n",
        "   <br>d) Calculating p-values\n",
        "\n",
        "5. What is the purpose of p-values in hypothesis testing?\n",
        "   <br>a) To determine the effect size of a statistical test\n",
        "   <br>b) To determine the power of a statistical test\n",
        "   <br>c) To assess the strength of evidence against the null hypothesis\n",
        "   <br>d) To compare two sample means\n",
        "\n",
        "6. How can you perform a correlation analysis between two columns in a pandas DataFrame?\n",
        "   <br>a) df.correlation()\n",
        "   <br>b) df.corr()\n",
        "   <br>c) df.calculate_correlation()\n",
        "   <br>d) df.column_correlation()\n",
        "\n",
        "7. What does covariance measure in statistics?\n",
        "   <br>a) The strength and direction of the linear relationship between two variables\n",
        "   <br>b) The spread and dispersion of a dataset\n",
        "   <br>c) The relationship between independent and dependent variables\n",
        "   <br>d) The average deviation from the mean of two variables\n",
        "\n",
        "8. Which function in pandas is used to aggregate data and create cross-tabulations?\n",
        "   <br>a) groupby()\n",
        "   <br>b) aggregate()\n",
        "   <br>c) cross_tab()\n",
        "   <br>d) pivot_table()\n",
        "---\n",
        "**Answers:**\n",
        "\n",
        "1. b) Pandas\n",
        "2. a) read_csv()\n",
        "3. a) df.mean()\n",
        "4. c) Testing a claim or assumption about a population parameter\n",
        "5. c) To assess the strength of evidence against the null hypothesis\n",
        "6. b) df.corr()\n",
        "7. d) The average deviation from the mean of two variables\n",
        "8. d) pivot_table()\n",
        "---"
      ],
      "metadata": {
        "id": "l7-dDh5TduCS"
      }
    }
  ]
}
