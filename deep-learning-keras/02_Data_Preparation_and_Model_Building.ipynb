{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNPzLjRCfxuUqjV5ARivh8i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cloudpedagogy/data-science-programming/blob/main/deep-learning-keras/02_Data_Preparation_and_Model_Building.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Building\n"
      ],
      "metadata": {
        "id": "jZl1hYqVETIj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview"
      ],
      "metadata": {
        "id": "LwDlfAT8uB7B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model building in deep learning is a crucial process that involves designing, creating, and training neural network architectures to solve complex problems and make predictions based on input data. Deep learning models are a subset of artificial intelligence that aim to mimic the human brain's structure and functioning, allowing them to learn patterns and representations from large amounts of data. This overview will provide a high-level understanding of the key steps involved in model building in deep learning:\n",
        "\n",
        "1. Data Collection and Preprocessing:\n",
        "The first step in model building is to collect and prepare the data. High-quality data is essential for training accurate deep learning models. This involves gathering relevant datasets, cleaning the data to handle missing values and outliers, and transforming the data into a suitable format for training.\n",
        "\n",
        "2. Defining the Architecture:\n",
        "The architecture of a deep learning model refers to its overall structure, including the number and types of layers, the number of neurons in each layer, and how they are interconnected. The choice of architecture depends on the specific task at hand, such as image classification, natural language processing, or time series forecasting.\n",
        "\n",
        "3. Choosing Activation Functions:\n",
        "Activation functions introduce non-linearity to the model, allowing it to learn complex patterns in the data. Common activation functions include ReLU (Rectified Linear Unit), sigmoid, and tanh. The selection of appropriate activation functions is crucial for the model's performance.\n",
        "\n",
        "4. Building the Model:\n",
        "After defining the architecture and activation functions, the model is constructed using deep learning frameworks or libraries like TensorFlow or PyTorch. These libraries provide convenient interfaces for creating and configuring neural networks.\n",
        "\n",
        "5. Compiling the Model:\n",
        "Before training the model, it needs to be compiled with an appropriate optimizer, loss function, and evaluation metrics. The optimizer, such as Adam or SGD (Stochastic Gradient Descent), updates the model's weights during training to minimize the loss function. The loss function quantifies the difference between the predicted outputs and the true labels, guiding the model to make better predictions.\n",
        "\n",
        "6. Training the Model:\n",
        "During the training phase, the model is exposed to the training data, and the weights of the neural network are adjusted iteratively to minimize the loss function. The process involves forward propagation (making predictions) and backward propagation (updating weights through backpropagation) for each batch of data.\n",
        "\n",
        "7. Hyperparameter Tuning:\n",
        "Deep learning models have several hyperparameters, such as learning rate, batch size, and the number of epochs. Optimizing these hyperparameters can significantly impact the model's performance. Hyperparameter tuning involves experimenting with different values and selecting the best configuration based on performance metrics.\n",
        "\n",
        "8. Evaluating the Model:\n",
        "Once the model is trained, it needs to be evaluated on a separate validation or test dataset to assess its performance. Common evaluation metrics for classification tasks include accuracy, precision, recall, and F1 score, while regression tasks may use mean squared error (MSE) or mean absolute error (MAE).\n",
        "\n",
        "9. Fine-tuning and Regularization:\n",
        "To further enhance the model's performance and prevent overfitting, techniques such as regularization (e.g., L1 and L2 regularization) and dropout can be applied. Fine-tuning the model involves adjusting the model's parameters or using transfer learning from pre-trained models to improve performance on specific tasks.\n",
        "\n",
        "10. Deployment and Inference:\n",
        "After successfully building and evaluating the model, it can be deployed to make predictions on new, unseen data. This involves feeding the new data into the trained model and obtaining predictions or classifications based on the learned patterns.\n",
        "\n",
        "In conclusion, model building in deep learning is a multidimensional process that requires careful consideration of data, architecture, hyperparameters, and evaluation metrics. By iteratively refining these components, developers can create powerful and accurate deep learning models capable of solving a wide range of real-world problems."
      ],
      "metadata": {
        "id": "UWKsITDZuEQe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model and making predictions\n"
      ],
      "metadata": {
        "id": "UHRlq-WWPiVy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Let's use the Pima Indians Diabetes dataset to build a simple deep learning model in Keras. This example will take you through loading the data, preparing it, defining the model, compiling the model, fitting the model, and making predictions.\n",
        "\n",
        "Firstly, we need to install necessary packages such as pandas and keras. If they're not installed you can use the following commands in Jupyter notebook:\n",
        "\n",
        "**Step 1: Load the Data**\n",
        "\n"
      ],
      "metadata": {
        "id": "Ovg3FXtYFt6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "names = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\n",
        "data = pd.read_csv(url, names=names)\n"
      ],
      "metadata": {
        "id": "eoqfA0z2F-Ev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Preparing the Data**\n",
        "Here, we'll split the dataset into input features (X) and the feature to predict (Y).\n"
      ],
      "metadata": {
        "id": "vUaroMJPGmop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into input (X) and target (Y)\n",
        "X = data.iloc[:, 0:8]\n",
        "Y = data.iloc[:, 8]\n"
      ],
      "metadata": {
        "id": "Qk42Xr-EGovs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is also a good practice to normalize the input data, using techniques such as Z-Score normalization or Min-Max Scaling. But to keep this example simple, we won't do it here.\n",
        "\n",
        "**Step 3: Define the Model**\n",
        "Next, let's define our deep learning model. We'll create a simple model with one hidden layer.\n"
      ],
      "metadata": {
        "id": "0zUk06sTGrVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Define the keras model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n"
      ],
      "metadata": {
        "id": "KujMX63DGxPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: Compile the Model**\n",
        "Before we can run the model, we need to compile it.\n"
      ],
      "metadata": {
        "id": "_Od_YYJ2G0a1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the keras model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "D4cpIX2FG3Rq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5: Fit the Model**\n",
        "Let's fit the model to our data.\n"
      ],
      "metadata": {
        "id": "JwG8m-wqG5z5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the keras model on the dataset\n",
        "model.fit(X, Y, epochs=150, batch_size=10)\n"
      ],
      "metadata": {
        "id": "_G-coOHWG--d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 6: Making Predictions**\n",
        "Now, we can make predictions on new data. But for simplicity, we'll just reuse our training data.\n"
      ],
      "metadata": {
        "id": "UxwrDcJ9HDqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make probability predictions with the model\n",
        "predictions = model.predict(X)\n",
        "# Round predictions\n",
        "rounded = [round(x[0]) for x in predictions]\n"
      ],
      "metadata": {
        "id": "N_CjV8l1HGiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that there are many ways to improve this model. Here we didn't split the data into training and test datasets, nor did we use cross-validation, in order to keep the example simple. In a real application, you'd want to do that, and also experiment with different model structures, different forms of regularization, and other techniques to optimize your model's performance. You might also want to save your trained model's weights for future use, which you can do using Keras's model.save() function.\n"
      ],
      "metadata": {
        "id": "vrLsWt4xHMGa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reflection Points"
      ],
      "metadata": {
        "id": "B_k7JufAHepR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Data Cleaning, Transformation, and Preparation for Modeling**:\n",
        "   - How do you handle missing values in a dataset? (Answer: Missing values can be imputed using techniques such as mean, median, or interpolation, or the rows with missing values can be dropped depending on the context.)\n",
        "   - What are some common techniques for handling outliers in data? (Answer: Outliers can be detected and treated using methods like statistical measures, z-scores, or percentiles.)\n",
        "   - Why is feature scaling important in machine learning models? (Answer: Feature scaling ensures that different features have a similar scale, preventing certain features from dominating the model's learning process.)\n",
        "\n",
        "2. **Building and Compiling a Keras Model**:\n",
        "   - How do you define a sequential model in Keras? (Answer: A sequential model is defined by stacking layers one after another using the `Sequential` class in Keras.)\n",
        "   - What are activation functions and why are they used in neural networks? (Answer: Activation functions introduce non-linearity and help the model learn complex patterns in the data.)\n",
        "   - What is the purpose of compiling a Keras model? (Answer: Compiling a model defines the loss function, optimizer, and metrics to be used during the training process.)\n",
        "\n",
        "3. **Training the Model and Making Predictions**:\n",
        "   - How do you split a dataset into training and testing sets? (Answer: The dataset can be split using functions like `train_test_split` from scikit-learn, allocating a certain percentage of the data for testing.)\n",
        "   - What is the purpose of training a machine learning model? (Answer: Training involves fitting the model to the training data, allowing it to learn the underlying patterns and relationships in the data.)\n",
        "   - How do you evaluate the performance of a trained model? (Answer: Performance evaluation can be done using metrics such as accuracy, precision, recall, F1-score, or using techniques like cross-validation.)\n"
      ],
      "metadata": {
        "id": "9rhI45ZXHku3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise"
      ],
      "metadata": {
        "id": "o6bKsS7lzDjN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Task 1: Data Preparation and Preprocessing\n",
        "\n",
        "1. Load the dataset from the given URL.\n",
        "2. Explore the dataset and check for any missing values.\n",
        "3. Split the dataset into features (X) and the target variable (y).\n",
        "4. Split the data into training and testing sets.\n",
        "\n",
        "Task 2: Build and Train the Neural Network\n",
        "\n",
        "1. Build a sequential neural network using Keras with the following architecture:\n",
        "   - Input layer with appropriate input shape (number of features in X).\n",
        "   - One or more hidden layers with ReLU activation.\n",
        "   - Output layer with a sigmoid activation function (since it's a binary classification problem).\n",
        "\n",
        "2. Compile the model with an appropriate loss function and optimizer for binary classification.\n",
        "3. Train the model using the training data for a reasonable number of epochs.\n",
        "\n",
        "Task 3: Evaluate the Model\n",
        "\n",
        "1. Evaluate the trained model using the testing data.\n",
        "2. Calculate the accuracy and other relevant metrics (e.g., precision, recall, F1-score) for the model's performance.\n",
        "\n"
      ],
      "metadata": {
        "id": "z7UWW75ezLVi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sample Solution"
      ],
      "metadata": {
        "id": "IIGATkk9zXZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Task 1: Data Preparation and Preprocessing\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "names = [\"preg\", \"plas\", \"pres\", \"skin\", \"insu\", \"mass\", \"pedi\", \"age\", \"class\"]\n",
        "df = pd.read_csv(url, names=names)\n",
        "\n",
        "# Check for missing values\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Split features (X) and target variable (y)\n",
        "X = df.iloc[:, :-1].values\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Task 2: Build and Train the Neural Network\n",
        "model = Sequential()\n",
        "model.add(Dense(8, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dense(4, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=10, verbose=1)\n",
        "\n",
        "# Task 3: Evaluate the Model\n",
        "_, accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Accuracy: {:.2f}%\".format(accuracy * 100))\n"
      ],
      "metadata": {
        "id": "SQ9v0i6ezaip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A quiz on Model Building"
      ],
      "metadata": {
        "id": "pqjZNiDaucBv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. What is Keras?\n",
        "   <br>a) A deep learning library for Java\n",
        "   <br>b) A high-level API for building and training deep learning models\n",
        "   <br>c) A programming language for machine learning\n",
        "   <br>d) A database management system\n",
        "\n",
        "2. What does the `Sequential` model in Keras allow you to do?\n",
        "   <br>a) Build complex recurrent neural networks\n",
        "   <br>b) Stack layers linearly to create feedforward neural networks\n",
        "   <br>c) Create unsupervised learning models\n",
        "   <br>d) Combine different types of neural network architectures\n",
        "\n",
        "3. How do you add layers to a Keras model?\n",
        "   <br>a) `add_layer()` method\n",
        "   <br>b) `add()` function\n",
        "   <br>c) `add_layer()` function\n",
        "   <br>d) `add()` method\n",
        "\n",
        "4. What is the purpose of compiling a Keras model?\n",
        "   <br>a) Save the model to disk\n",
        "   <br>b) Prepare the model for deployment\n",
        "   <br>c) Convert the model to TensorFlow format\n",
        "   <br>d) Specify the optimizer, loss function, and metrics for training\n",
        "\n",
        "5. Which optimizer is commonly used in Keras for stochastic gradient descent?\n",
        "   <br>a) RMSprop\n",
        "   <br>b) AdaBoost\n",
        "   <br>c) L-BFGS\n",
        "   <br>d) Adam\n",
        "\n",
        "6. What is the purpose of the `fit()` method in Keras?\n",
        "   <br>a) Evaluate the model on a test dataset\n",
        "   <br>b) Fine-tune the model's hyperparameters\n",
        "   <br>c) Compile the model with an optimizer\n",
        "   <br>d) Train the model on training data\n",
        "\n",
        "7. How do you evaluate a trained Keras model on a test dataset?\n",
        "   <br>a) `evaluate_model()`\n",
        "   <br>b) `evaluate()`\n",
        "   <br>c) `predict()`\n",
        "   <br>d) `score()`\n",
        "\n",
        "8. What is a common technique used to prevent overfitting in Keras models?\n",
        "   <br>a) Data augmentation\n",
        "   <br>b) Early stopping\n",
        "   <br>c) Dropout\n",
        "   <br>d) Batch normalization\n",
        "\n",
        "---\n",
        "**Answers:**\n",
        "\n",
        "1. b) A high-level API for building and training deep learning models.\n",
        "\n",
        "2. b) Stack layers linearly to create feedforward neural networks.\n",
        "\n",
        "3. d) `add()` method.\n",
        "\n",
        "4. d) Specify the optimizer, loss function, and metrics for training.\n",
        "\n",
        "5. d) Adam.\n",
        "\n",
        "6. d) Train the model on training data.\n",
        "\n",
        "7. b) `evaluate()`.\n",
        "\n",
        "8. c) Dropout.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "2III5J9wufNJ"
      }
    }
  ]
}