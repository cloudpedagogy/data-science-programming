{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOmNTaDkYZu5lkTaWZUfz7s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cloudpedagogy/data-science-programming/blob/main/statistics-scipy/04_Probability_distributions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Understanding probability distributions: Normal, Binomial, Poisson\n"
      ],
      "metadata": {
        "id": "WfDT3BheX0Um"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview"
      ],
      "metadata": {
        "id": "28r5HTBJQO3g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "In data science, probability distributions play a crucial role in describing and modeling random variables and their outcomes. Understanding different probability distributions is essential for making data-driven decisions, performing statistical analysis, and building predictive models. Let's explore three common probability distributions used in data science:\n",
        "\n",
        "1. **Normal Distribution:**\n",
        "   - Also known as the Gaussian distribution, it is one of the most important and widely used probability distributions.\n",
        "   - The probability density function (PDF) of a normal distribution is characterized by its mean (μ) and standard deviation (σ).\n",
        "   - It is symmetric and bell-shaped, with the peak at the mean, and tails extending to infinity.\n",
        "   - Many natural phenomena, such as heights, weights, and measurement errors, tend to follow a normal distribution.\n",
        "   - The central limit theorem states that the sum of a large number of independent, identically distributed random variables will be approximately normally distributed, regardless of the original distribution of the variables.\n",
        "\n",
        "2. **Binomial Distribution:**\n",
        "   - The binomial distribution models the number of successes in a fixed number of independent Bernoulli trials.\n",
        "   - A Bernoulli trial is an experiment with two possible outcomes, often referred to as \"success\" and \"failure,\" with a fixed probability of success (p) and failure (1-p).\n",
        "   - The binomial distribution is characterized by two parameters: the number of trials (n) and the probability of success (p).\n",
        "   - Examples of scenarios following a binomial distribution include coin flips, success/failure experiments, and click-through rates in online advertising.\n",
        "\n",
        "3. **Poisson Distribution:**\n",
        "   - The Poisson distribution models the number of events that occur in a fixed interval of time or space.\n",
        "   - It is appropriate for situations where events happen independently and with a constant average rate (λ) over time or space.\n",
        "   - The probability mass function (PMF) of the Poisson distribution is characterized by its mean (λ).\n",
        "   - Examples of scenarios following a Poisson distribution include the number of arrivals at a store, the number of customer service calls in an hour, or the number of defects in a product.\n",
        "\n",
        "In data science, the choice of which distribution to use depends on the nature of the data and the problem at hand. Properly understanding and applying these probability distributions help data scientists gain insights from data, build accurate models, and make informed decisions in various domains, including finance, healthcare, marketing, and more."
      ],
      "metadata": {
        "id": "9kURgxBMQRUR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normal distribution\n"
      ],
      "metadata": {
        "id": "AFinV6zvPn8u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The SciPy library in Python provides a suite of functions that allow you to work with different probability distributions including the Normal Distribution (also known as Gaussian Distribution).\n",
        "\n",
        "Here, we'll load the Pima Indians Diabetes dataset and visualize a histogram and probability density function (PDF) for a normally distributed feature, such as BMI.\n",
        "\n",
        "Firstly, let's load the data:\n"
      ],
      "metadata": {
        "id": "-5JONUJuX4CY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "names = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\n",
        "df = pd.read_csv(url, names=names)\n"
      ],
      "metadata": {
        "id": "UJufIP75X7uL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's analyze the 'BMI' column:\n"
      ],
      "metadata": {
        "id": "ZHtzII_VX-q_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "# isolate BMI values\n",
        "bmi_values = df['BMI'].values\n",
        "\n",
        "# calculate mean and standard deviation\n",
        "mu, std = np.mean(bmi_values), np.std(bmi_values)\n",
        "\n",
        "# create a range of values for x (from -4*stddev to +4*stddev)\n",
        "x = np.linspace(mu - 4*std, mu + 4*std, 100)\n",
        "\n",
        "# plot histogram\n",
        "plt.hist(bmi_values, bins=30, density=True, alpha=0.6, color='g')\n",
        "\n",
        "# plot PDF\n",
        "plt.plot(x, norm.pdf(x, mu, std), color='crimson')\n",
        "\n",
        "plt.title('BMI Distribution with PDF')\n",
        "plt.xlabel('BMI')\n",
        "plt.ylabel('Density')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "016L6x-NYDfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the code snippet above, we first isolate the BMI values from the dataframe, then calculate their mean and standard deviation. These are the parameters of the normal distribution.\n",
        "\n",
        "Next, we generate a range of x values that span 4 standard deviations on either side of the mean. We then plot the histogram of the BMI values and the PDF of a normal distribution with the same mean and standard deviation.\n",
        "\n",
        "Note that the histogram is \"normalized\" (`density=True`) so that it forms a probability density (i.e., the area under the histogram integrates to 1). This allows it to be properly compared with the PDF.\n",
        "\n",
        "Remember that not all data are normally distributed, and you should always perform statistical tests (like the Shapiro-Wilk test) to confirm if the data follows a normal distribution. It's also worth noting that BMI values should ideally not be zero in the context of this dataset, so further data cleaning might be required.\n"
      ],
      "metadata": {
        "id": "YeDRo1l6YH3h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Binomial distribution\n"
      ],
      "metadata": {
        "id": "cd0Fzr4XPqb1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The binomial distribution is a probability distribution that describes the number of successes in a fixed number of independent Bernoulli trials, each with the same probability of success.\n",
        "\n",
        "In the context of the Pima Indians Diabetes dataset, one way to use the binomial distribution is to simulate the distribution of diabetes occurrence given the probabilities observed in the dataset. Let's see how we can do this with SciPy and pandas.\n",
        "\n",
        "**Step 1: Load Libraries and Data**\n"
      ],
      "metadata": {
        "id": "hp0glc-LYK8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import binom\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# load data\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "names = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\n",
        "dataframe = pd.read_csv(url, names=names)\n"
      ],
      "metadata": {
        "id": "qdZkrV6zYSzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Compute the Probability of Diabetes**\n"
      ],
      "metadata": {
        "id": "vSEnAat5YViy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the probability of diabetes\n",
        "prob_diabetes = dataframe['Outcome'].mean()\n"
      ],
      "metadata": {
        "id": "2hpr9YEJYYAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Simulate Binomial Trials**\n"
      ],
      "metadata": {
        "id": "k3YqQic_Yaxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# number of trials and probability of success\n",
        "n = 10\n",
        "p = prob_diabetes\n",
        "\n",
        "# simulate binomial distribution\n",
        "r_values = list(range(n + 1))\n",
        "dist = [binom.pmf(r, n, p) for r in r_values]\n"
      ],
      "metadata": {
        "id": "tm4eLp98Yd6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: Plot the Binomial Distribution**\n"
      ],
      "metadata": {
        "id": "0MN-sDYYYgi1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the distribution\n",
        "plt.bar(r_values, dist)\n",
        "plt.title('Binomial Distribution of Diabetes Occurrence')\n",
        "plt.xlabel('Number of Diabetes Cases')\n",
        "plt.ylabel('Probability')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "WDkPGkTmYjcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This will create a bar plot of the binomial distribution of diabetes occurrence in a sample of 10 individuals, based on the probability of diabetes occurrence in the dataset.\n"
      ],
      "metadata": {
        "id": "IwdKZkCHYpaz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Poisson distribution\n"
      ],
      "metadata": {
        "id": "tDocuqVRPtuJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The Poisson distribution is a discrete probability distribution often used to model the number of times an event happened in a time interval. For instance, it can describe the number of users visited on a website in an interval of time, given the average number of visits.\n",
        "\n",
        "In this example, we will analyze the number of pregnancies from the Pima Indian dataset. We'll assume that this number follows a Poisson distribution. Here is how you can use the `scipy` library to work with the Poisson distribution:\n",
        "\n"
      ],
      "metadata": {
        "id": "HEvSZCOsYtF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import poisson\n",
        "\n",
        "# load data\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "names = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\n",
        "dataframe = pd.read_csv(url, names=names)\n",
        "\n",
        "# data\n",
        "data = dataframe['Pregnancies']\n",
        "\n",
        "# the average number of pregnancies in the dataset\n",
        "mu = data.mean()\n",
        "\n",
        "# PMF\n",
        "print(\"Probability mass function: \", poisson.pmf(3, mu)) # probability of exactly 3 pregnancies\n",
        "\n",
        "# CDF\n",
        "print(\"Cumulative distribution function: \", poisson.cdf(3, mu)) # probability of 3 or fewer pregnancies\n",
        "\n",
        "# Random variates\n",
        "print(\"Random variates: \", poisson.rvs(mu, size=10))  # generate 10 random numbers from poisson distribution with mean mu\n"
      ],
      "metadata": {
        "id": "wUKkqo-vd_Fd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that this is a simplification. The number of pregnancies in the dataset might not follow a Poisson distribution in reality, and we are treating it as such for illustrative purposes. For real-world data analysis, it's important to carefully consider the underlying assumptions and validate them using appropriate statistical tests or graphical checks.\n",
        "\n",
        "Remember to replace `'Pregnancies'` with the actual name of your column if it's different. If you want to analyze a different column, ensure that column represents count data (i.e., non-negative integer values), as the Poisson distribution is defined for such data.\n"
      ],
      "metadata": {
        "id": "e_9vSmndeDF-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hypothesis testing: Null Hypothesis, Alternate Hypothesis, p-value\n"
      ],
      "metadata": {
        "id": "k_wDLAiNPwo-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview"
      ],
      "metadata": {
        "id": "VhPP4XtjQqkJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Hypothesis testing is a fundamental concept in statistics and data science that allows us to make decisions or draw conclusions about a population based on sample data. It involves formulating two competing hypotheses, the null hypothesis and the alternative hypothesis, and then using statistical methods to evaluate the evidence in the data to support one of the hypotheses.\n",
        "\n",
        "1. **Null Hypothesis (H0):**\n",
        "   The null hypothesis is the default or the status quo hypothesis. It states that there is no significant difference, effect, or relationship between the variables of interest in the population. In other words, any observed differences or patterns in the sample data are due to random chance or sampling variability.\n",
        "\n",
        "   For example, if we are testing the effectiveness of a new drug, the null hypothesis would state that the drug has no effect on the condition being treated.\n",
        "\n",
        "2. **Alternative Hypothesis (Ha or H1):**\n",
        "   The alternative hypothesis is the opposite of the null hypothesis. It represents what the researcher wants to establish or show evidence for. It proposes that there is a significant difference, effect, or relationship between the variables in the population, beyond random chance.\n",
        "\n",
        "   In the drug example, the alternative hypothesis would state that the new drug has a significant effect on the condition being treated.\n",
        "\n",
        "3. **p-value:**\n",
        "   The p-value is a probability value that measures the strength of the evidence against the null hypothesis. It quantifies the likelihood of obtaining the observed results (or more extreme results) if the null hypothesis were true. A small p-value suggests that the observed data is unlikely to occur under the null hypothesis, providing evidence in favor of the alternative hypothesis.\n",
        "\n",
        "   In general, a common significance level (alpha) is set, often at 0.05. If the calculated p-value is less than or equal to the significance level, we reject the null hypothesis in favor of the alternative hypothesis. If the p-value is greater than the significance level, we fail to reject the null hypothesis (note: failing to reject the null hypothesis does not mean that we accept it as true).\n",
        "\n",
        "   For example, if the p-value is 0.03 and the significance level is 0.05, we would reject the null hypothesis because the p-value is less than the significance level.\n",
        "\n",
        "In conclusion, hypothesis testing is a powerful tool that helps data scientists and researchers make data-driven decisions. By formulating null and alternative hypotheses and calculating p-values, we can determine whether the observed data provides enough evidence to support the alternative hypothesis or if the results are simply due to chance and should be attributed to the null hypothesis."
      ],
      "metadata": {
        "id": "qYmSiuNNQtlm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Here's a simple example using the Pima Indian Diabetes dataset to perform a hypothesis test. For this demonstration, we'll use the BMI (Body Mass Index) variable and test the hypothesis that the average BMI of the population is 30.\n",
        "\n",
        "**Step 1: Load Libraries and Data**\n"
      ],
      "metadata": {
        "id": "buQLSse7eFsE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy import stats\n",
        "\n",
        "# load data\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "names = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\n",
        "dataframe = pd.read_csv(url, names=names)\n"
      ],
      "metadata": {
        "id": "phuR0EKDeOg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Define Hypotheses**\n",
        "\n",
        "* Null Hypothesis (H0): The mean BMI of the population is 30.\n",
        "* Alternative Hypothesis (H1): The mean BMI of the population is not 30.\n",
        "\n",
        "**Step 3: Conduct Hypothesis Test**\n",
        "\n",
        "We can perform a One-Sample T-Test to test our hypothesis. A one-sample t-test is a statistical procedure used to determine whether a sample of observations could have been generated by a process with a specific mean.\n"
      ],
      "metadata": {
        "id": "zpP2YuRyeRw5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bmi_values = dataframe['BMI'].values\n",
        "\n",
        "tset, pval = stats.ttest_1samp(bmi_values, 30)\n",
        "\n",
        "print('p-values',pval)\n",
        "\n",
        "if pval < 0.05:    # alpha value is 0.05 or 5%\n",
        "   print(\"We are rejecting null hypothesis\")\n",
        "else:\n",
        "  print(\"We are accepting null hypothesis\")\n"
      ],
      "metadata": {
        "id": "Zsi1L5Jweacw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This test returns a p-value. If the p-value is below our significance level (often 0.05), we reject the null hypothesis. If it's greater, we cannot reject the null hypothesis.\n",
        "\n",
        "In the example above, if the p-value is less than 0.05, we reject the null hypothesis that the average BMI is 30, and infer the average BMI is different from 30. If the p-value is greater than 0.05, we cannot reject the null hypothesis that the average BMI is 30.\n",
        "\n",
        "Remember that \"failing to reject\" the null hypothesis is not the same as \"accepting\" it. Your test is simply saying that the data isn't convincing enough to say for certain that the null is untrue.\n"
      ],
      "metadata": {
        "id": "d8b8Z9nQeeQC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Types of errors in hypothesis testing: Type I and Type II\n"
      ],
      "metadata": {
        "id": "-mipVpxZPysW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the context of hypothesis testing, the two types of errors we look for are Type I and Type II errors:\n",
        "\n",
        "1. **Type I Error (False Positive):** When the null hypothesis is true and we incorrectly reject it. It's also known as a \"false alarm\" or \"false positive\". The probability of committing a Type I error is denoted by the significance level α.\n",
        "\n",
        "2. **Type II Error (False Negative):** When the null hypothesis is false and we fail to reject it. It's also known as a \"miss\" or \"false negative\". The probability of committing a Type II error is denoted by β. The power of a test (1 - β) is the probability that it correctly rejects a false null hypothesis.\n",
        "\n",
        "To illustrate these concepts with an example, we'll use the Pima Indian Diabetes dataset and perform a hypothesis test on whether the average Glucose level differs for people with diabetes and people without.\n"
      ],
      "metadata": {
        "id": "gReI_F0GehS5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy import stats\n",
        "\n",
        "# Load dataset\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "names = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\n",
        "dataframe = pd.read_csv(url, names=names)\n",
        "\n",
        "# Split the dataset based on Outcome\n",
        "diabetes_positive = dataframe[dataframe['Outcome'] == 1]\n",
        "diabetes_negative = dataframe[dataframe['Outcome'] == 0]\n",
        "\n",
        "# Conduct a two-sample t-test\n",
        "t_stat, p_val = stats.ttest_ind(diabetes_positive['Glucose'], diabetes_negative['Glucose'], equal_var=False, nan_policy='omit')\n",
        "\n",
        "print(f\"T-statistic: {t_stat}\")\n",
        "print(f\"P-value: {p_val}\")\n"
      ],
      "metadata": {
        "id": "7BZnhoQzemP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the p-value is less than our chosen significance level (say 0.05), we reject the null hypothesis and infer that there is a significant difference in average glucose levels for individuals with and without diabetes. If we falsely reject the null hypothesis (i.e., in reality, there's no difference), that's a Type I error.\n",
        "\n",
        "If the p-value is more significant than our chosen significance level, we fail to reject the null hypothesis and infer that there is no significant difference in average glucose levels. If in reality there is a difference (we failed to detect it), that's a Type II error.\n",
        "\n",
        "Remember, these are probabilistic inferences. A low p-value means that our observed data is highly unlikely under the null hypothesis, not that the null hypothesis is definitely false. Similarly, failing to reject the null hypothesis doesn't prove it true. It merely suggests that we don't have strong enough evidence to conclude otherwise.\n"
      ],
      "metadata": {
        "id": "26GZcJ3fep_U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reflection Points"
      ],
      "metadata": {
        "id": "vVuYa3ogetH0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Normal Distribution**\n",
        "   - What is the normal distribution, and why is it important in statistics?\n",
        "   - How is the normal distribution characterized, and what are its key properties?\n",
        "   - How do you generate random numbers following a normal distribution using Scipy?\n",
        "   - How do you calculate the probability density function (PDF) and cumulative distribution function (CDF) of a normal distribution using Scipy?\n",
        "   - How can you perform statistical tests and confidence interval calculations based on the normal distribution using Scipy?\n",
        "\n",
        "2. **Binomial Distribution**\n",
        "   - What is the binomial distribution, and in what scenarios is it applicable?\n",
        "   - How is the binomial distribution defined, and what are its parameters?\n",
        "   - How do you generate random numbers following a binomial distribution using Scipy?\n",
        "   - How can you calculate the probability mass function (PMF) and cumulative distribution function (CDF) of a binomial distribution using Scipy?\n",
        "   - How can you use the binomial distribution for hypothesis testing and confidence interval estimation using Scipy?\n",
        "\n",
        "3. **Poisson Distribution**\n",
        "   - What is the Poisson distribution, and when is it commonly used?\n",
        "   - How is the Poisson distribution defined, and what are its characteristics?\n",
        "   - How do you generate random numbers following a Poisson distribution using Scipy?\n",
        "   - How can you calculate the probability mass function (PMF) and cumulative distribution function (CDF) of a Poisson distribution using Scipy?\n",
        "   - How can you utilize the Poisson distribution in various applications, such as modeling rare events, queuing theory, and counting processes?\n"
      ],
      "metadata": {
        "id": "ak6T95TWewp-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise"
      ],
      "metadata": {
        "id": "Y0QgI0t6Reiu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. Load the Pima Indian Diabetes dataset into a pandas DataFrame.\n",
        "2. Choose one numerical feature from the dataset to analyze its probability distribution.\n",
        "3. Compute descriptive statistics (mean, median, standard deviation, etc.) for the chosen feature.\n",
        "4. Plot a histogram to visualize the distribution.\n",
        "5. Determine the best-fitting probability distribution for the data and fit it using `scipy.stats`.\n",
        "6. Plot the probability density function (PDF) of the best-fitting distribution along with the histogram.\n",
        "7. Calculate the cumulative distribution function (CDF) for the data and plot it.\n",
        "8. Generate random samples from the fitted distribution and compare them with the original data.\n"
      ],
      "metadata": {
        "id": "CdVXtN-ERqtG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "column_names = [\"preg\", \"plas\", \"pres\", \"skin\", \"test\", \"mass\", \"pedi\", \"age\", \"class\"]\n",
        "data = pd.read_csv(url, names=column_names)\n",
        "\n",
        "# Step 2: Choose a numerical feature to analyze its probability distribution\n",
        "chosen_feature = \"plas\"  # We choose the \"plas\" feature (plasma glucose concentration).\n",
        "\n",
        "# Step 3: Compute descriptive statistics\n",
        "feature_data = data[chosen_feature]\n",
        "mean_value = np.mean(feature_data)\n",
        "median_value = np.median(feature_data)\n",
        "std_deviation = np.std(feature_data)\n",
        "\n",
        "print(\"Descriptive Statistics for {}: \".format(chosen_feature))\n",
        "print(\"Mean: {:.2f}\".format(mean_value))\n",
        "print(\"Median: {:.2f}\".format(median_value))\n",
        "print(\"Standard Deviation: {:.2f}\".format(std_deviation))\n",
        "\n",
        "# Step 4: Plot a histogram to visualize the distribution\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.hist(feature_data, bins=20, edgecolor=\"k\", alpha=0.7)\n",
        "plt.xlabel(chosen_feature)\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Histogram of {}\".format(chosen_feature))\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Step 5: Fit a probability distribution to the data\n",
        "best_fit_distribution = stats.norm  # We assume a normal distribution for this example\n",
        "params = best_fit_distribution.fit(feature_data)\n",
        "print(\"Best-fitting distribution parameters:\", params)\n",
        "\n",
        "# Step 6: Plot the PDF of the best-fitting distribution\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.hist(feature_data, bins=20, density=True, alpha=0.7, label=\"Data\")\n",
        "x = np.linspace(np.min(feature_data), np.max(feature_data), 100)\n",
        "pdf = best_fit_distribution.pdf(x, *params)\n",
        "plt.plot(x, pdf, 'r', label=\"Best-Fitting PDF\")\n",
        "plt.xlabel(chosen_feature)\n",
        "plt.ylabel(\"Probability Density\")\n",
        "plt.title(\"PDF of {} and Best-Fitting Distribution\".format(chosen_feature))\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Step 7: Calculate the CDF and plot it\n",
        "plt.figure(figsize=(8, 6))\n",
        "cdf = np.linspace(0, 1, len(feature_data))\n",
        "plt.plot(np.sort(feature_data), cdf, label=\"CDF\")\n",
        "plt.xlabel(chosen_feature)\n",
        "plt.ylabel(\"Cumulative Probability\")\n",
        "plt.title(\"CDF of {}\".format(chosen_feature))\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Step 8: Generate random samples from the fitted distribution and compare with original data\n",
        "random_samples = best_fit_distribution.rvs(*params, size=len(feature_data))\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.hist(feature_data, bins=20, density=True, alpha=0.7, label=\"Data\")\n",
        "plt.hist(random_samples, bins=20, density=True, alpha=0.7, label=\"Random Samples\")\n",
        "plt.xlabel(chosen_feature)\n",
        "plt.ylabel(\"Probability Density\")\n",
        "plt.title(\"Comparison: Original Data vs. Random Samples\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "WdmS93mnRhmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A quiz on Probability distributions"
      ],
      "metadata": {
        "id": "G2q15jvvRdat"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Question 1: What type of probability distribution is appropriate to model the number of successes in a fixed number of independent Bernoulli trials?\n",
        "<br>a) Normal Distribution\n",
        "<br>b) Binomial Distribution\n",
        "<br>c) Poisson Distribution\n",
        "\n",
        "Question 2: The sum of a large number of independent, identically distributed random variables with finite variance will tend to follow which distribution?\n",
        "<br>a) Normal Distribution\n",
        "<br>b) Binomial Distribution\n",
        "<br>c) Poisson Distribution\n",
        "\n",
        "Question 3: Which probability distribution is commonly used to describe continuous random variables with a symmetric bell-shaped curve?\n",
        "<br>a) Normal Distribution\n",
        "<br>b) Binomial Distribution\n",
        "<br>c) Poisson Distribution\n",
        "\n",
        "Question 4: In hypothesis testing, the statement that there is no significant difference between specified populations is called:\n",
        "<br>a) Null Hypothesis\n",
        "<br>b) Alternate Hypothesis\n",
        "<br>c) P-value\n",
        "\n",
        "Question 5: The probability of making a Type I error in hypothesis testing is represented by:\n",
        "<br>a) Alpha (α)\n",
        "<br>b) Beta (β)\n",
        "<br>c) P-value\n",
        "\n",
        "Question 6: The probability of making a Type II error in hypothesis testing is represented by:\n",
        "<br>a) Alpha (α)\n",
        "<br>b) Beta (β)\n",
        "<br>c) P-value\n",
        "\n",
        "Question 7: Which of the following is NOT a step in hypothesis testing?\n",
        "<br>a) Formulating the null hypothesis\n",
        "<br>b) Selecting the level of significance\n",
        "<br>c) Computing the p-value\n",
        "\n",
        "Question 8: The probability value (p-value) in hypothesis testing represents:\n",
        "<br>a) The probability of the null hypothesis being true\n",
        "<br>b) The probability of obtaining the observed results by chance, assuming the null hypothesis is true\n",
        "<br>c) The probability of making a Type I error\n",
        "\n",
        "Question 9: In a binomial distribution, if the number of trials increases and the probability of success remains constant, what happens to the shape of the distribution?\n",
        "<br>a) It becomes narrower and taller\n",
        "<br>b) It becomes wider and flatter\n",
        "<br>c) It remains the same\n",
        "\n",
        "Question 10: Which scipy function can be used to generate random numbers from a normal distribution?\n",
        "<br>a) scipy.random.normal\n",
        "<br>b) scipy.stats.norm\n",
        "<br>c) scipy.random.binomial\n",
        "\n",
        "---\n",
        "Answers:\n",
        "\n",
        "<br>1) b) Binomial Distribution\n",
        "<br>2) a) Normal Distribution\n",
        "<br>3) a) Normal Distribution\n",
        "<br>4) a) Null Hypothesis\n",
        "<br>5) a) Alpha (α)\n",
        "<br>6) b) Beta (β)\n",
        "<br>7) c) Computing the p-value\n",
        "<br>8) b) The probability of obtaining the observed results by chance, assuming the null hypothesis is true\n",
        "<br>9) b) It becomes wider and flatter\n",
        "<br>10) a) scipy.random.normal\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "OB7KZh_YRgUz"
      }
    }
  ]
}